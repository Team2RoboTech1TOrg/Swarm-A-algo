{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69bfd55b-6e7d-4c6e-99e7-891cd24b7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл one.py\n",
    "\n",
    "# =============================================================================\n",
    "# Импорты\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import heapq\n",
    "import enum\n",
    "from math import ceil, radians\n",
    "from collections import deque\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, List, Tuple, Optional, Dict, Set\n",
    "from functools import lru_cache\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# =============================================================================\n",
    "# Константы\n",
    "# =============================================================================\n",
    "\n",
    "# ----------------------\n",
    "# Параметры модели\n",
    "# ----------------------\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.99\n",
    "CLIP_RANGE = 0.2\n",
    "N_STEPS = 4096\n",
    "COEF = 0.001\n",
    "VF_COEF = 0.6\n",
    "CLIP_RANGE_VF = 0.2\n",
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ----------------------\n",
    "# Параметры экрана и сетки\n",
    "# ----------------------\n",
    "SCREEN_SIZE = 900\n",
    "STATUS_PANEL_WIDTH = 300  # Ширина панели статуса справа\n",
    "BAR_HEIGHT = int(SCREEN_SIZE * 0.13)\n",
    "GRID_SIZE = 20\n",
    "MARGIN_SIZE = 1\n",
    "\n",
    "# ----------------------\n",
    "# Параметры игры\n",
    "# ----------------------\n",
    "NUM_AGENTS = 3\n",
    "COUNT_TARGETS = 100  # ceil((GRID_SIZE ** 2) * 0.4)\n",
    "COUNT_OBSTACLES = 12  # ceil((GRID_SIZE ** 2) * 0.03)\n",
    "STATION_SIZE = 2\n",
    "MAX_STEPS_GAME = (GRID_SIZE ** 2) * 10\n",
    "VIEW_RANGE = 1  # Область зрения 3x3\n",
    "ON_TARGET_CONSUMPTION = 10  # Расход воды\n",
    "TANK_CAPACITY = (COUNT_TARGETS * ON_TARGET_CONSUMPTION) / 2  # Максимальный запас воды\n",
    "ENERGY_CAPACITY = 1000  # Максимальный запас топлива\n",
    "ENERGY_CONSUMPTION_MOVE = 1\n",
    "ENERGY_CONSUMPTION_DONE = 2\n",
    "COUNT_ACTIONS = 4\n",
    "MIN_GAME_STEPS = (GRID_SIZE * GRID_SIZE // NUM_AGENTS) * 2\n",
    "\n",
    "# ----------------------\n",
    "# Награды\n",
    "# ----------------------\n",
    "REWARD_EXPLORE = 5  # Вознаграждение за исследование новых клеток\n",
    "REWARD_DONE = 3\n",
    "REWARD_COMPLETION = (REWARD_DONE * COUNT_TARGETS) * 10\n",
    "PENALTY_LOOP = 1\n",
    "PENALTY_OUT_FIELD = 2\n",
    "PENALTY_OBSTACLE = 2\n",
    "PENALTY_CRASH = 3\n",
    "\n",
    "# ----------------------\n",
    "# Позиции\n",
    "# ----------------------\n",
    "PLACEMENT_MODE = 'random'\n",
    "\n",
    "FIXED_TARGET_POSITIONS = [\n",
    "    (2, 2), (2, 8), (4, 3), (4, 7), (6, 2),\n",
    "    (6, 8), (8, 4), (8, 6), (3, 5), (7, 5)\n",
    "]\n",
    "\n",
    "FIXED_OBSTACLE_POSITIONS = [\n",
    "    (1, 1), (1, 9), (3, 3), (7, 7), (9, 5)\n",
    "]\n",
    "\n",
    "# ----------------------\n",
    "# Цвета\n",
    "# ----------------------\n",
    "WHITE = (200, 200, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "GREEN = (34, 139, 34)\n",
    "BLUE = (0, 0, 255)\n",
    "RED = (255, 69, 0)\n",
    "GRAY = (30, 30, 30)\n",
    "YELLOW = (255, 255, 0)\n",
    "LIGHT_BLUE = (173, 216, 230)\n",
    "\n",
    "# ----------------------\n",
    "# Изображения\n",
    "# ----------------------\n",
    "AGENT_IMG = \"images/drone.png\"\n",
    "TARGET_IMG = \"images/bad_plant.png\"\n",
    "DONE_TARGET_IMG = \"images/healthy_plant.png\"\n",
    "OBSTACLES_DIR = \"./images/obstacles\"\n",
    "STATION_IMG = \"images/robdocst.png\"\n",
    "FIELD_IMG = \"images/field.png\"\n",
    "FIELD_BACKGROUND_IMG = \"images/forest.jpg\"\n",
    "\n",
    "# ----------------------\n",
    "# Логирование\n",
    "# ----------------------\n",
    "LOG_DIR = \"./logs\"\n",
    "LOG_FILE = os.path.join(LOG_DIR, 'logging.log')\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.DEBUG,  # Уровень логирования изменен на INFO для более подробного отслеживания\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Перечисления\n",
    "# =============================================================================\n",
    "\n",
    "class PointStatus(enum.Enum):\n",
    "    \"\"\"Статусы точек на карте.\"\"\"\n",
    "    EMPTY = 0\n",
    "    VIEWED = 1\n",
    "    VISITED = 2\n",
    "\n",
    "class ObjectStatus(enum.Enum):\n",
    "    \"\"\"Статусы объектов на карте.\"\"\"\n",
    "    EMPTY = 0\n",
    "    OBSTACLE = 1\n",
    "    TARGET = 2\n",
    "\n",
    "# =============================================================================\n",
    "# Утилиты\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(filename: str, cell_size: int) -> pygame.Surface:\n",
    "    \"\"\"\n",
    "    Загружает и масштабирует изображение для объектов.\n",
    "    Используется многопоточность для предварительной загрузки изображений.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = pygame.image.load(filename).convert_alpha()\n",
    "        return pygame.transform.scale(image, (cell_size, cell_size))\n",
    "    except pygame.error as e:\n",
    "        logging.error(f\"Не удалось загрузить изображение {filename}: {e}\")\n",
    "        return pygame.Surface((cell_size, cell_size), pygame.SRCALPHA)\n",
    "\n",
    "def load_obstacles(directory: str, cell_size: int, count: int) -> List[pygame.Surface]:\n",
    "    \"\"\"\n",
    "    Загружает случайные изображения препятствий из указанного каталога.\n",
    "    Использует многопоточность для ускорения загрузки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        all_files = [\n",
    "            os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        selected_files = random.sample(all_files, min(count, len(all_files)))\n",
    "        return [load_image(f, cell_size) for f in selected_files]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка загрузки препятствий из {directory}: {e}\")\n",
    "        return []\n",
    "\n",
    "def render_text(\n",
    "    screen: pygame.Surface,\n",
    "    text: Any,\n",
    "    font: pygame.font.Font,\n",
    "    color: Tuple[int, int, int],\n",
    "    x: int,\n",
    "    y: int\n",
    ") -> pygame.Rect:\n",
    "    \"\"\"\n",
    "    Отображает текст на экране pygame и возвращает область отрисовки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_surface = font.render(str(text), True, color)\n",
    "        rect = text_surface.get_rect(topleft=(x, y))\n",
    "        screen.blit(text_surface, rect)\n",
    "        return rect\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при отображении текста: {e}\")\n",
    "        return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "# =============================================================================\n",
    "# Менеджер Pygame\n",
    "# =============================================================================\n",
    "\n",
    "class PygameManager:\n",
    "    \"\"\"\n",
    "    Класс для централизованного управления инициализацией и ресурсами pygame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, width: int, height: int):\n",
    "        pygame.init()\n",
    "        self.screen = None\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "\n",
    "    def create_screen(self) -> None:\n",
    "        \"\"\"\n",
    "        Создает окно pygame.\n",
    "        \"\"\"\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "            logging.info(f\"Создано окно pygame размером {self.width}x{self.height}\")\n",
    "\n",
    "    def quit(self) -> None:\n",
    "        \"\"\"Завершает работу pygame.\"\"\"\n",
    "        pygame.quit()\n",
    "        logging.info(\"pygame завершил работу\")\n",
    "\n",
    "# =============================================================================\n",
    "# Классы\n",
    "# =============================================================================\n",
    "\n",
    "class AStarPathfinder:\n",
    "    \"\"\"\n",
    "    Класс для реализации алгоритма A* поиска пути с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache: Dict[Tuple[Tuple[int, int], Tuple[Tuple[int, int], ...]], Optional[List[Tuple[int, int]]]] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def heuristic(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "        \"\"\"Манхэттенское расстояние между двумя точками.\"\"\"\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "    def find_path(\n",
    "        self,\n",
    "        start: Tuple[int, int],\n",
    "        goals: Set[Tuple[int, int]],\n",
    "        known_map: np.ndarray,\n",
    "        grid_size: int,\n",
    "        occupied_positions: Set[Tuple[int, int]]\n",
    "    ) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь от старта до одной из целей с использованием A* и кэшированием.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Сортировка целей по эвристике для более быстрой остановки\n",
    "            sorted_goals = sorted(goals, key=lambda goal: self.heuristic(start, goal))\n",
    "            \n",
    "            if not sorted_goals:\n",
    "                logging.warning(\"No goals provided for pathfinding\")\n",
    "                return None\n",
    "\n",
    "            goals_tuple = tuple(sorted_goals)\n",
    "\n",
    "            cache_key = (start, goals_tuple)\n",
    "            if cache_key in self.cache:\n",
    "                return self.cache[cache_key]\n",
    "\n",
    "            open_heap = []\n",
    "            heapq.heappush(open_heap, (0, start))\n",
    "            came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "            g_score = {start: 0}\n",
    "            f_score = {start: self.heuristic(start, sorted_goals[0])}\n",
    "\n",
    "            open_set = {start}\n",
    "            closed_set = set()\n",
    "\n",
    "            while open_heap:\n",
    "                current_f, current = heapq.heappop(open_heap)\n",
    "                open_set.remove(current)\n",
    "\n",
    "                if current in goals:\n",
    "                    # Восстанавливаем путь\n",
    "                    path = []\n",
    "                    while current in came_from:\n",
    "                        path.append(current)\n",
    "                        current = came_from[current]\n",
    "                    path.append(start)\n",
    "                    path.reverse()\n",
    "                    self.cache[cache_key] = path\n",
    "                    logging.debug(f\"Найден путь: {path}\")\n",
    "                    return path\n",
    "\n",
    "                closed_set.add(current)\n",
    "\n",
    "                neighbors = [\n",
    "                    (current[0] + dx, current[1] + dy)\n",
    "                    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "                ]\n",
    "\n",
    "                for neighbor in neighbors:\n",
    "                    if not (0 <= neighbor[0] < grid_size and 0 <= neighbor[1] < grid_size):\n",
    "                        continue\n",
    "                    if known_map[neighbor[0]][neighbor[1]][1] == ObjectStatus.OBSTACLE.value:\n",
    "                        continue\n",
    "                    if neighbor in occupied_positions:\n",
    "                        continue\n",
    "                    if neighbor in closed_set:\n",
    "                        continue\n",
    "\n",
    "                    tentative_g_score = g_score[current] + 1\n",
    "\n",
    "                    if tentative_g_score < g_score.get(neighbor, float('inf')):\n",
    "                        came_from[neighbor] = current\n",
    "                        g_score[neighbor] = tentative_g_score\n",
    "                        # Улучшенная эвристика: сортировка целей позволяет использовать минимальную эвристику\n",
    "                        f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, sorted_goals[0])\n",
    "                        if neighbor not in open_set:\n",
    "                            heapq.heappush(open_heap, (f_score[neighbor], neighbor))\n",
    "                            open_set.add(neighbor)\n",
    "\n",
    "            logging.debug(\"Путь не найден\")\n",
    "            self.cache[cache_key] = None\n",
    "            return None  # Путь не найден\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в AStarPathfinder.find_path: {e}\")\n",
    "            return None\n",
    "\n",
    "class Renderer:\n",
    "    \"\"\"\n",
    "    Класс для управления процессом рендеринга с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pygame_manager: PygameManager, grid_size: int, cell_size: int, status_panel_width: int):\n",
    "        \"\"\"\n",
    "        Инициализирует Renderer.\n",
    "        \"\"\"\n",
    "        self.pygame_manager = pygame_manager\n",
    "        self.grid_size = grid_size\n",
    "        self.cell_size = cell_size\n",
    "        self.status_panel_width = status_panel_width\n",
    "        self.screen = pygame_manager.screen\n",
    "        self.base_icons: Dict[str, pygame.Surface] = {}\n",
    "        self.text_cache: Dict[str, pygame.Rect] = {}\n",
    "        self.load_icons()\n",
    "\n",
    "    def load_icons(self) -> None:\n",
    "        \"\"\"Загружает все необходимые иконки.\"\"\"\n",
    "        try:\n",
    "            # Использование многопоточности для загрузки изображений\n",
    "            def load_all():\n",
    "                self.base_icons['agent'] = load_image(AGENT_IMG, self.cell_size)\n",
    "                self.base_icons['target'] = load_image(TARGET_IMG, self.cell_size)\n",
    "                self.base_icons['done_target'] = load_image(DONE_TARGET_IMG, self.cell_size)\n",
    "                self.base_icons['base'] = load_image(STATION_IMG, self.cell_size * STATION_SIZE)\n",
    "                self.base_icons['field_bg'] = pygame.transform.smoothscale(\n",
    "                    load_image(FIELD_BACKGROUND_IMG, self.grid_size * self.cell_size),\n",
    "                    (self.grid_size * self.cell_size, self.grid_size * self.cell_size)\n",
    "                )\n",
    "                self.base_icons['field'] = pygame.transform.smoothscale(\n",
    "                    load_image(FIELD_IMG, self.grid_size * self.cell_size),\n",
    "                    (self.grid_size * self.cell_size, self.grid_size * self.cell_size)\n",
    "                )\n",
    "\n",
    "            load_thread = Thread(target=load_all)\n",
    "            load_thread.start()\n",
    "            load_thread.join()\n",
    "            logging.info(\"Иконки успешно загружены\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка загрузки иконок: {e}\")\n",
    "\n",
    "    def draw_grid(self) -> None:\n",
    "        \"\"\"Отрисовывает сетку на экране.\"\"\"\n",
    "        try:\n",
    "            grid_surface = pygame.Surface((self.grid_size * self.cell_size, self.grid_size * self.cell_size), pygame.SRCALPHA)\n",
    "            for x in range(self.grid_size):\n",
    "                for y in range(self.grid_size):\n",
    "                    pygame.draw.rect(\n",
    "                        grid_surface, BLACK,\n",
    "                        (x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size), 1\n",
    "                    )\n",
    "            self.screen.blit(grid_surface, (0, 0))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке сетки: {e}\")\n",
    "\n",
    "    def draw_base(self, base_position: Tuple[int, int]) -> pygame.Rect:\n",
    "        \"\"\"Отрисовывает базу на экране и возвращает область обновления.\"\"\"\n",
    "        try:\n",
    "            base_size = STATION_SIZE * self.cell_size\n",
    "            base_icon_scaled = pygame.transform.smoothscale(self.base_icons['base'], (base_size, base_size))\n",
    "            rect = self.screen.blit(\n",
    "                base_icon_scaled,\n",
    "                (base_position[1] * self.cell_size, base_position[0] * self.cell_size)\n",
    "            )\n",
    "            return rect\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке базы: {e}\")\n",
    "            return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "    def draw_objects(\n",
    "        self,\n",
    "        target_positions: List[Tuple[int, int]],\n",
    "        done_status: np.ndarray,\n",
    "        obstacle_positions: Set[Tuple[int, int]],\n",
    "        current_map: np.ndarray,\n",
    "        obstacle_icons: List[pygame.Surface]\n",
    "    ) -> List[pygame.Rect]:\n",
    "        \"\"\"\n",
    "        Отрисовывает цели и препятствия на экране.\n",
    "        Возвращает список обновлённых областей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            for index, target in enumerate(target_positions):\n",
    "                x, y = target\n",
    "                if current_map[x, y, 0] != PointStatus.EMPTY.value:\n",
    "                    if index < len(done_status):\n",
    "                        icon = self.base_icons['done_target'] if done_status[index] else self.base_icons['target']\n",
    "                    else:\n",
    "                        icon = self.base_icons['target']  # По умолчанию, если индекс выходит за пределы\n",
    "                    rect = self.screen.blit(icon, (y * self.cell_size, x * self.cell_size))\n",
    "                    rects.append(rect)\n",
    "\n",
    "            for obstacle in obstacle_positions:\n",
    "                x, y = obstacle\n",
    "                if current_map[x, y, 0] != PointStatus.EMPTY.value:\n",
    "                    obstacle_icon = obstacle_icons[hash(obstacle) % len(obstacle_icons)]\n",
    "                    rect = self.screen.blit(obstacle_icon, (y * self.cell_size, x * self.cell_size))\n",
    "                    rects.append(rect)\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке объектов: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_agents(self, agents: List['Agent']) -> List[pygame.Rect]:\n",
    "        \"\"\"Отрисовывает агентов на экране и возвращает список обновлённых областей.\"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            for agent in agents:\n",
    "                if agent.position:\n",
    "                    agent_image = self.base_icons['agent']\n",
    "                    rect = self.screen.blit(\n",
    "                        agent_image,\n",
    "                        (agent.position[1] * self.cell_size, agent.position[0] * self.cell_size)\n",
    "                    )\n",
    "                    rects.append(rect)\n",
    "\n",
    "                    # Рисуем прогресс-бары для топлива и воды на панели статуса\n",
    "                    # Эти прогресс-бары будут рисоваться на панели, а не рядом с агентом\n",
    "                    # Поэтому здесь ничего не делаем для прогресс-баров\n",
    "\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке агентов: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_progress_bars(self, agents: List['Agent'], font: pygame.font.Font) -> List[pygame.Rect]:\n",
    "        \"\"\"\n",
    "        Отрисовывает прогресс-бары для топлива и воды каждого агента на панели статуса.\n",
    "        Возвращает список обновлённых областей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            bar_width = self.status_panel_width - 40\n",
    "            bar_height = 20\n",
    "            for idx, agent in enumerate(agents):\n",
    "                # Определяем позиции для каждой строки информации\n",
    "                base_x = self.grid_size * self.cell_size + 20\n",
    "                base_y = 20 + idx * 100\n",
    "\n",
    "                # Заголовок агента\n",
    "                text = f\"Дрон {idx + 1}\"\n",
    "                rect = render_text(\n",
    "                    self.screen, text, font, BLACK, base_x, base_y\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "                # Топливо\n",
    "                fuel_text = \"Топливо:\"\n",
    "                rect = render_text(\n",
    "                    self.screen, fuel_text, font, BLACK, base_x, base_y + 30\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "                fuel_percentage = max(0, min(100, (agent.fuel_level / 100.0)))\n",
    "                fuel_bar_rect = pygame.Rect(base_x + 80, base_y + 30, bar_width, bar_height)\n",
    "                pygame.draw.rect(self.screen, BLACK, fuel_bar_rect, 2)  # Рамка\n",
    "                pygame.draw.rect(self.screen, YELLOW, (base_x + 82, base_y + 32, (fuel_percentage / 100.0) * (bar_width - 4), bar_height - 4))\n",
    "                rects.append(fuel_bar_rect)\n",
    "\n",
    "                fuel_percent_text = f\"{int(fuel_percentage)}%\"\n",
    "                rect = render_text(\n",
    "                    self.screen, fuel_percent_text, font, BLACK, base_x + bar_width + 90, base_y + 30\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "                # Вода\n",
    "                water_text = \"Вода:\"\n",
    "                rect = render_text(\n",
    "                    self.screen, water_text, font, BLACK, base_x, base_y + 60\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "                water_percentage = max(0, min(100, (agent.water_level / 100.0)))\n",
    "                water_bar_rect = pygame.Rect(base_x + 80, base_y + 60, bar_width, bar_height)\n",
    "                pygame.draw.rect(self.screen, BLACK, water_bar_rect, 2)  # Рамка\n",
    "                pygame.draw.rect(self.screen, BLUE, (base_x + 82, base_y + 62, (water_percentage / 100.0) * (bar_width - 4), bar_height - 4))\n",
    "                rects.append(water_bar_rect)\n",
    "\n",
    "                water_percent_text = f\"{int(water_percentage)}%\"\n",
    "                rect = render_text(\n",
    "                    self.screen, water_percent_text, font, BLACK, base_x + bar_width + 90, base_y + 60\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке прогресс-баров: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_status_panel(\n",
    "        self,\n",
    "        agents: List['Agent'],\n",
    "        total_steps: int,\n",
    "        total_points: int,\n",
    "        detected_flowers: int,\n",
    "        sprayed_flowers: int\n",
    "    ) -> List[pygame.Rect]:\n",
    "        \"\"\"\n",
    "        Отрисовывает горизонтальную панель статуса справа от игрового поля.\n",
    "        Возвращает список обновлённых областей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            base_x = self.grid_size * self.cell_size + 20\n",
    "            base_y = self.grid_size * self.cell_size + 20\n",
    "\n",
    "            # Заголовок панели\n",
    "            font = pygame.font.SysFont('Arial', 24)\n",
    "            text = \"Статус\"\n",
    "            rect = render_text(\n",
    "                self.screen, text, font, BLACK, base_x, 10\n",
    "            )\n",
    "            rects.append(rect)\n",
    "\n",
    "            # Общая статистика\n",
    "            stats = [\n",
    "                f\"Шаги: {total_steps}\",\n",
    "                f\"Очки: {total_points}\",\n",
    "                f\"Обнаружено цветков: {detected_flowers}\",\n",
    "                f\"Полито цветков: {sprayed_flowers}\"\n",
    "            ]\n",
    "            for idx, stat in enumerate(stats):\n",
    "                rect = render_text(\n",
    "                    self.screen, stat, font, BLACK, base_x, 50 + idx * 30\n",
    "                )\n",
    "                rects.append(rect)\n",
    "\n",
    "            # Прогресс-бары для каждого агента\n",
    "            progress_rects = self.draw_progress_bars(agents, font)\n",
    "            rects.extend(progress_rects)\n",
    "\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке панели статуса: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_overlay(self, current_map: np.ndarray) -> List[pygame.Rect]:\n",
    "        \"\"\"Накладывает тёмный оверлей на неизведанные области и возвращает список обновлённых областей.\"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            dark_overlay = pygame.Surface((self.cell_size, self.cell_size), pygame.SRCALPHA)\n",
    "            dark_overlay.fill((0, 0, 0, 200))  # Непрозрачный\n",
    "\n",
    "            for x in range(self.grid_size):\n",
    "                for y in range(self.grid_size):\n",
    "                    if current_map[x, y, 0] == PointStatus.EMPTY.value:\n",
    "                        rect = self.screen.blit(dark_overlay, (y * self.cell_size, x * self.cell_size))\n",
    "                        rects.append(rect)\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при наложении оверлея: {e}\")\n",
    "            return []\n",
    "\n",
    "    def render_message(self, message: str, color_title: Tuple[int, int, int] = RED, color_body: Tuple[int, int, int] = GREEN) -> pygame.Rect:\n",
    "        \"\"\"\n",
    "        Отображает сообщение в центре экрана и возвращает область обновления.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.screen.fill(GRAY)\n",
    "\n",
    "            lines = message.split('\\n')\n",
    "            screen_width, screen_height = self.screen.get_size()\n",
    "\n",
    "            # Настройка шрифтов\n",
    "            font_title = pygame.font.SysFont('Arial', ceil(SCREEN_SIZE * 0.05))\n",
    "            font_body = pygame.font.SysFont('Arial', ceil(SCREEN_SIZE * 0.03))\n",
    "\n",
    "            total_height = 0\n",
    "            rects = []\n",
    "            for i, line in enumerate(lines):\n",
    "                if i == 0:\n",
    "                    font = font_title\n",
    "                    color = color_title\n",
    "                else:\n",
    "                    font = font_body\n",
    "                    color = color_body\n",
    "                text_surface = font.render(line, True, color)\n",
    "                text_width, text_height = font.size(line)\n",
    "                x = (screen_width - text_width) // 2\n",
    "                y = (screen_height - len(lines) * text_height) // 2 + total_height\n",
    "                rect = self.screen.blit(text_surface, (x, y))\n",
    "                rects.append(rect)\n",
    "                total_height += text_height + 5\n",
    "\n",
    "            pygame.display.update(rects)\n",
    "            pygame.time.wait(10)\n",
    "            return pygame.Rect(0, 0, screen_width, screen_height)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отображении сообщения: {e}\")\n",
    "            return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "class BaseScenario(ABC):\n",
    "    \"\"\"\n",
    "    Базовый абстрактный класс для сценариев игры.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self) -> Tuple[Dict[str, Any], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"Выполняет один шаг сценария.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"Сбрасывает сценарий в исходное состояние.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def render(self) -> None:\n",
    "        \"\"\"Отображает текущее состояние сценария.\"\"\"\n",
    "        pass\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Класс, представляющий агента в сценарии.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scenario: 'SprayingScenario', name: str = None):\n",
    "        \"\"\"\n",
    "        Инициализирует агента.\n",
    "        \"\"\"\n",
    "        self.name = name or f'agent_{id(self)}'\n",
    "        self.env = scenario\n",
    "        self.position: Optional[Tuple[int, int]] = None\n",
    "        self.tank: Optional[int] = None  # Вода\n",
    "        self.energy: Optional[int] = None  # Топливо\n",
    "        self.position_history: Optional[deque] = None\n",
    "        self.action_space = list(range(COUNT_ACTIONS))\n",
    "        self.observation_space: Optional[Dict[str, Any]] = None\n",
    "        self.fuel_level: float = 100.0  # Уровень топлива в процентах\n",
    "        self.water_level: float = 100.0  # Уровень воды в процентах\n",
    "        self.known_targets: Set[Tuple[int, int]] = set()  # Добавлено\n",
    "\n",
    "    def reset(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Сбрасывает состояние агента.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.position = random.choice(list(self.env.base_positions))\n",
    "            logging.info(f\"Позиция {self.name} стартовая {self.position}\")\n",
    "            self.position_history = deque(maxlen=10)\n",
    "            self.tank = TANK_CAPACITY\n",
    "            self.energy = ENERGY_CAPACITY\n",
    "            self.fuel_level = 100.0\n",
    "            self.water_level = 100.0\n",
    "            coords = np.zeros((self.env.grid_size, self.env.grid_size, 2), dtype=np.int8)  # Изменен тип данных\n",
    "            self.observation_space = {\n",
    "                'pos': self.position,\n",
    "                'coords': coords\n",
    "            }\n",
    "            return self.observation_space\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе reset агента {self.name}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def refuel(self) -> None:\n",
    "        \"\"\"\n",
    "        Пополняет танк и энергию агента до максимальных значений.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.tank = TANK_CAPACITY\n",
    "            self.energy = ENERGY_CAPACITY\n",
    "            self.fuel_level = 100.0\n",
    "            self.water_level = 100.0\n",
    "            logging.info(f\"{self.name} заправился на базе. Танк и энергия восстановлены.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе refuel агента {self.name}: {e}\")\n",
    "    \n",
    "    def take_action(self) -> Tuple[Tuple[int, int], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Определяет и выполняет действие агента.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "\n",
    "        try:\n",
    "            # Проверка уровней топлива и воды\n",
    "            if self.fuel_level <= 10 or self.water_level <= 10:\n",
    "                logging.info(f\"{self.name} возвращается на базу из-за низкого уровня топлива или воды\")\n",
    "                path_to_base = self.env.pathfinder.find_path(\n",
    "                    start=self.position,\n",
    "                    goals=self.env.base_positions,\n",
    "                    known_map=self.env.current_map,\n",
    "                    grid_size=self.env.grid_size,\n",
    "                    occupied_positions=self.env.occupied_positions - {self.position}\n",
    "                )\n",
    "                if path_to_base and len(path_to_base) > 1:\n",
    "                    next_position = path_to_base[1]\n",
    "                    action = self._determine_action(self.position, next_position)\n",
    "                else:\n",
    "                    action = random.choice(self.action_space)\n",
    "            else:\n",
    "                obs = self.get_observation()\n",
    "                # Выбор действия на основе наличия целей или необходимости разведки\n",
    "                #visible_targets = self.get_visible_targets(obs['coords'])\n",
    "                # visible_targets = self.get_visible_targets(self.env.current_map)\n",
    "                visible_targets = obs.get('visible_targets', [])\n",
    "                unexplored_cells = self.get_unexplored_cells()\n",
    "                explored_unsprayed = self.env.get_explored_unsprayed_cells()\n",
    "                \n",
    "                if visible_targets:\n",
    "                    # Если цели видны, направляемся к ближайшей\n",
    "                    closest_visible_target = min(\n",
    "                        visible_targets,\n",
    "                        key=lambda t: self.heuristic(self.position, t)\n",
    "                    )\n",
    "                    path = self.env.pathfinder.find_path(\n",
    "                        start=self.position,\n",
    "                        goals={closest_visible_target},\n",
    "                        known_map=self.env.current_map,\n",
    "                        grid_size=self.env.grid_size,\n",
    "                        occupied_positions=self.env.occupied_positions - {self.position}\n",
    "                    )\n",
    "                elif explored_unsprayed:\n",
    "                    # Стремимся к разведанным, но непролитым клеткам\n",
    "                    closest_explored_unsprayed = min(\n",
    "                        explored_unsprayed,\n",
    "                        key=lambda t: self.heuristic(self.position, t)\n",
    "                    )\n",
    "                    path = self.env.pathfinder.find_path(\n",
    "                        start=self.position,\n",
    "                        goals={closest_explored_unsprayed},\n",
    "                        known_map=self.env.current_map,\n",
    "                        grid_size=self.env.grid_size,\n",
    "                        occupied_positions=self.env.occupied_positions - {self.position}\n",
    "                    )\n",
    "                    logging.debug(f\"{self.name} найден путь к разведанной непролитой клетке {closest_explored_unsprayed}: {path}\")    \n",
    "                elif unexplored_cells:\n",
    "                    # Можно выбрать ближайшую неизведанную клетку\n",
    "                    closest_unexplored = min(\n",
    "                        unexplored_cells,\n",
    "                        key=lambda t: self.heuristic(self.position, t)\n",
    "                    )\n",
    "                    path = self.env.pathfinder.find_path(\n",
    "                        start=self.position,\n",
    "                        goals={closest_unexplored},\n",
    "                        known_map=self.env.current_map,\n",
    "                        grid_size=self.env.grid_size,\n",
    "                        occupied_positions=self.env.occupied_positions - {self.position}\n",
    "                    )\n",
    "                else:\n",
    "                    # Если все клетки исследованы, выбираем случайное действие\n",
    "                    path = None\n",
    "                    logging.debug(f\"{self.name} не находит видимых целей или неизведанных клеток\")\n",
    "                if path and len(path) > 1:\n",
    "                    next_position = path[1]\n",
    "                    action = self._determine_action(self.position, next_position)\n",
    "                else:\n",
    "                    action = random.choice(self.action_space)\n",
    "                    logging.debug(f\"{self.name} выбирает случайное действие {action}\")\n",
    "            # Выполнение действия\n",
    "            new_position, reward_increment = self.execute_action(action)\n",
    "            reward += reward_increment\n",
    "\n",
    "            # Проверка на заправку, если агент находится на базе\n",
    "            if new_position in self.env.base_positions:\n",
    "                self.refuel()\n",
    "            \n",
    "            return new_position, reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе take_action агента {self.name}: {e}\")\n",
    "            return self.position, 0, False, False, {}\n",
    "\n",
    "    def execute_action(self, action: int) -> Tuple[Tuple[int, int], int]:\n",
    "        \"\"\"\n",
    "        Выполняет выбранное действие и обновляет состояние агента.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        try:\n",
    "            # Выполнение действия\n",
    "            if action == 0:  # Вверх\n",
    "                new_position = (max(0, self.position[0] - 1), self.position[1])\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 1:  # Вниз\n",
    "                new_position = (min(self.env.grid_size - 1, self.position[0] + 1), self.position[1])\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 2:  # Влево\n",
    "                new_position = (self.position[0], max(0, self.position[1] - 1))\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 3:  # Вправо\n",
    "                new_position = (self.position[0], min(self.env.grid_size - 1, self.position[1] + 1))\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            else:\n",
    "                new_position = self.position\n",
    "\n",
    "            # Обновление уровней топлива и воды\n",
    "            self.fuel_level = max(0.0, min(100.0, (self.energy / ENERGY_CAPACITY) * 100))\n",
    "            self.water_level = max(0.0, min(100.0, (self.tank / TANK_CAPACITY) * 100))\n",
    "\n",
    "            obs = self.get_observation()\n",
    "            value_new_position = obs['coords'][new_position[0]][new_position[1]]\n",
    "            new_position, agent_reward = self.get_agent_rewards(new_position, value_new_position)\n",
    "            self.position = new_position\n",
    "            logging.info(f\"Действие: {action} - позиция: {self.position} - {self.name}\")\n",
    "\n",
    "            return new_position, agent_reward\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе execute_action агента {self.name}: {e}\")\n",
    "            return self.position, 0\n",
    "\n",
    "    def _determine_action(self, current: Tuple[int, int], next_pos: Tuple[int, int]) -> int:\n",
    "        \"\"\"\n",
    "        Определяет действие на основе текущей и следующей позиции.\n",
    "        \"\"\"\n",
    "        dx = next_pos[0] - current[0]\n",
    "        dy = next_pos[1] - current[1]\n",
    "        if dx == -1:\n",
    "            return 0  # Вверх\n",
    "        elif dx == 1:\n",
    "            return 1  # Вниз\n",
    "        elif dy == -1:\n",
    "            return 2  # Влево\n",
    "        elif dy == 1:\n",
    "            return 3  # Вправо\n",
    "        else:\n",
    "            return random.choice(self.action_space)\n",
    "\n",
    "    def get_observation(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Получает наблюдения агента.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            coords = np.zeros((self.env.grid_size, self.env.grid_size, 2), dtype=np.int8)\n",
    "            x, y = self.position\n",
    "            # Векторизация области зрения\n",
    "            x_min = max(x - VIEW_RANGE, 0)\n",
    "            x_max = min(x + VIEW_RANGE + 1, self.env.grid_size)\n",
    "            y_min = max(y - VIEW_RANGE, 0)\n",
    "            y_max = min(y + VIEW_RANGE + 1, self.env.grid_size)\n",
    "    \n",
    "            coords[x_min:x_max, y_min:y_max, 0] = PointStatus.VIEWED.value\n",
    "    \n",
    "            # Обновление статусов объектов с использованием Numpy\n",
    "            obstacle_indices = np.array(list(self.env.obstacle_positions))\n",
    "            target_indices = np.array(self.env.target_positions)\n",
    "    \n",
    "            if obstacle_indices.size > 0:\n",
    "                coords[obstacle_indices[:,0], obstacle_indices[:,1], 1] = ObjectStatus.OBSTACLE.value\n",
    "            if target_indices.size > 0:\n",
    "                coords[target_indices[:,0], target_indices[:,1], 1] = ObjectStatus.TARGET.value\n",
    "    \n",
    "            # Теперь вызываем get_visible_targets после обновления информации о целях\n",
    "            visible_targets = self.get_visible_targets(coords)\n",
    "    \n",
    "            # Объединение наблюдений\n",
    "            observation = {\n",
    "                'pos': self.position,\n",
    "                'coords': coords,\n",
    "                'energy': self.energy,\n",
    "                'tank': self.tank,\n",
    "                'visible_targets': visible_targets\n",
    "            }\n",
    "            self.observation_space = observation\n",
    "    \n",
    "            # Обновление известных целей\n",
    "            self.known_targets.update(visible_targets)\n",
    "    \n",
    "            return observation\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_observation агента {self.name}: {e}\")\n",
    "            return {}\n",
    "\n",
    "\n",
    "    def get_agent_rewards(\n",
    "        self,\n",
    "        new_position: Tuple[int, int],\n",
    "        value: np.ndarray\n",
    "    ) -> Tuple[Tuple[int, int], int]:\n",
    "        \"\"\"\n",
    "        Обновляет позиции, обрабатывает препятствия и цели, начисляет награды и штрафы.\n",
    "        \"\"\"\n",
    "        agent_reward = 0\n",
    "        try:\n",
    "            self.position_history.append(new_position)\n",
    "\n",
    "            if not self.is_within_bounds(new_position):\n",
    "                agent_reward -= PENALTY_OUT_FIELD\n",
    "                logging.warning(f\"Агент {self.name} вышел за границы поля: {new_position}\")\n",
    "                new_position = self.position\n",
    "            else:\n",
    "                if value[1] == ObjectStatus.OBSTACLE.value:\n",
    "                    agent_reward -= PENALTY_OBSTACLE\n",
    "                    new_position = self.position\n",
    "                    logging.info(\n",
    "                        f\"Упс, препятствие! {self.name} - штраф {PENALTY_OBSTACLE}, вернулся на {new_position}\"\n",
    "                    )\n",
    "                elif value[1] == ObjectStatus.TARGET.value:\n",
    "                    if new_position in self.env.target_positions:\n",
    "                        index = self.env.target_positions.index(new_position)\n",
    "                        if self.env.done_status[index] == 0:\n",
    "                            # Уменьшаем уровень воды при поливе\n",
    "                            self.water_level = max(0.0, self.water_level - (ON_TARGET_CONSUMPTION / TANK_CAPACITY) * 100)\n",
    "                            self.tank -= ON_TARGET_CONSUMPTION\n",
    "                            # Уменьшаем уровень топлива при поливе\n",
    "                            self.energy = max(0, self.energy - ENERGY_CONSUMPTION_DONE)\n",
    "                            self.fuel_level = max(0.0, (self.energy / ENERGY_CAPACITY) * 100)\n",
    "                            self.env.done_status[index] = 1\n",
    "                            agent_reward += REWARD_DONE\n",
    "                            logging.info(f\"Опрыскал растение {self.name} + награда {REWARD_DONE}\")\n",
    "                            # Увеличиваем счетчик политых цветков\n",
    "                            self.env.sprayed_flowers += 1\n",
    "                else:\n",
    "                    if len(self.position_history) > 3:\n",
    "                        pos_counter = self.position_history.count(new_position)\n",
    "                        if pos_counter >= 2:\n",
    "                            if new_position == self.position_history[-2]:\n",
    "                                agent_reward -= PENALTY_LOOP * 2\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за второй раз в одну клетку {self.position_history[-2]}\"\n",
    "                                )\n",
    "                            elif 2 < pos_counter < 4:\n",
    "                                agent_reward -= PENALTY_LOOP * 3\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за вторичное посещение {new_position} в последние 10 шагов\"\n",
    "                                )\n",
    "                            elif pos_counter >= 4:\n",
    "                                agent_reward -= PENALTY_LOOP * 5\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за многократное посещение {new_position} в последние 10 шагов\"\n",
    "                                )\n",
    "            return new_position, agent_reward\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_agent_rewards агента {self.name}: {e}\")\n",
    "            return self.position, 0\n",
    "\n",
    "    def is_within_bounds(self, position: Tuple[int, int]) -> bool:\n",
    "        \"\"\"\n",
    "        Проверяет, находится ли позиция внутри границ поля.\n",
    "        \"\"\"\n",
    "        return 0 <= position[0] < self.env.grid_size and 0 <= position[1] < self.env.grid_size\n",
    "\n",
    "    def find_path_to_position(\n",
    "        self,\n",
    "        target_position: Tuple[int, int]\n",
    "    ) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к заданной позиции с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals={target_position},\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions - {self.position}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_position агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_path_to_nearest_target(self) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к ближайшей цели с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals=set(self.get_remaining_targets()),\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions - {self.position}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_nearest_target агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_path_to_nearest_base(self) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к ближайшей базе с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals=self.env.base_positions,\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions - {self.position}\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_nearest_base агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_unexplored_cells(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Возвращает множество координат неизведанных клеток (EMPTY = 0).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            unexplored = set()\n",
    "            for x in range(self.env.grid_size):\n",
    "                for y in range(self.env.grid_size):\n",
    "                    if self.env.current_map[x, y, 0] == PointStatus.EMPTY.value:\n",
    "                        unexplored.add((x, y))\n",
    "            return unexplored\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_unexplored_cells агента {self.name}: {e}\")\n",
    "            return set()\n",
    "    \n",
    "    # def get_visible_targets(self, coords: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    #     \"\"\"\n",
    "    #     Возвращает список неполитых целей, находящихся в области зрения агента.\n",
    "    #     \"\"\"\n",
    "    #     try:\n",
    "    #         visible_targets = []\n",
    "    #         x, y = self.position\n",
    "    #         x_min = max(x - VIEW_RANGE, 0)\n",
    "    #         x_max = min(x + VIEW_RANGE + 1, self.env.grid_size)\n",
    "    #         y_min = max(y - VIEW_RANGE, 0)\n",
    "    #         y_max = min(y + VIEW_RANGE + 1, self.env.grid_size)\n",
    "\n",
    "    #         # Использование векторизации для ускорения\n",
    "    #         visible_coords = coords[x_min:x_max, y_min:y_max, 1]\n",
    "    #         target_indices = np.argwhere(visible_coords == ObjectStatus.TARGET.value)\n",
    "    #         for dx, dy in target_indices:\n",
    "    #             target_pos = (x_min + dx, y_min + dy)\n",
    "    #             if target_pos in self.get_remaining_targets():\n",
    "    #                 visible_targets.append(target_pos)\n",
    "    #         logging.debug(f\"{self.name} видит цели: {visible_targets}\")        \n",
    "    #         return visible_targets\n",
    "    #     except Exception as e:\n",
    "    #         logging.error(f\"Ошибка в методе get_visible_targets агента {self.name}: {e}\")\n",
    "    #         return []\n",
    "    def get_visible_targets(self, coords: np.ndarray) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Возвращает список неполитых целей, находящихся в области зрения агента,\n",
    "        а также уже известные (разведанные) цели.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            visible_targets = []\n",
    "            x, y = self.position\n",
    "            x_min = max(x - VIEW_RANGE, 0)\n",
    "            x_max = min(x + VIEW_RANGE + 1, self.env.grid_size)\n",
    "            y_min = max(y - VIEW_RANGE, 0)\n",
    "            y_max = min(y + VIEW_RANGE + 1, self.env.grid_size)\n",
    "    \n",
    "            # Использование векторизации для ускорения\n",
    "            visible_coords = coords[x_min:x_max, y_min:y_max, 1]\n",
    "            target_indices = np.argwhere(visible_coords == ObjectStatus.TARGET.value)\n",
    "            for dx, dy in target_indices:\n",
    "                target_pos = (x_min + dx, y_min + dy)\n",
    "                if target_pos in self.get_remaining_targets():\n",
    "                    visible_targets.append(target_pos)\n",
    "            \n",
    "            logging.debug(f\"{self.name} видит цели в зоне обзора: {visible_targets}\")\n",
    "    \n",
    "            # Получаем известные цели, которые не находятся в текущей зоне обзора\n",
    "            known_remaining_targets = self.known_targets.intersection(\n",
    "                {pos for pos, done in zip(self.env.target_positions, self.env.done_status) if done == 0}\n",
    "            )\n",
    "            # Исключаем из известных уже видимые цели, чтобы избежать дублирования\n",
    "            known_remaining_targets = known_remaining_targets.difference(set(visible_targets))\n",
    "            \n",
    "            logging.debug(f\"{self.name} известные цели вне зоны обзора: {known_remaining_targets}\")\n",
    "    \n",
    "            # Объединяем видимые цели с известными\n",
    "            all_targets = visible_targets + list(known_remaining_targets)\n",
    "            \n",
    "            logging.debug(f\"{self.name} все цели для рассмотрения: {all_targets}\")\n",
    "            \n",
    "            return all_targets\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_visible_targets агента {self.name}: {e}\")\n",
    "            return []\n",
    "\n",
    "    \n",
    "    def heuristic(self, a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "        \"\"\"\n",
    "        Манхэттенское расстояние между двумя точками.\n",
    "        \"\"\"\n",
    "        return AStarPathfinder.heuristic(a, b)\n",
    "\n",
    "\n",
    "    def get_remaining_targets(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"Возвращает известные агенту неполитые цели.\"\"\"\n",
    "        try:\n",
    "            # Извлекаем неполитые цели из глобального состояния\n",
    "            remaining_targets = {\n",
    "                pos for pos, done in zip(self.env.target_positions, self.env.done_status) if done == 0\n",
    "            }\n",
    "    \n",
    "            # Пересечение с известными агенту целями\n",
    "            remaining_known_targets = self.known_targets & remaining_targets\n",
    "    \n",
    "            logging.debug(\n",
    "                f\"{self.name} известные цели: {self.known_targets}, \"\n",
    "                f\"неполитые цели: {remaining_targets}, \"\n",
    "                f\"известные неполитые цели: {remaining_known_targets}\"\n",
    "            )\n",
    "    \n",
    "            return remaining_known_targets\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_remaining_targets агента {self.name}: {e}\")\n",
    "            return set()\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Agent {self.name}>'\n",
    "\n",
    "class SprayingScenario(BaseScenario):\n",
    "    \"\"\"\n",
    "    Класс сценария опрыскивания с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_agents: int, grid_size: int, renderer: Renderer):\n",
    "        \"\"\"\n",
    "        Инициализирует сценарий опрыскивания.\n",
    "        \"\"\"\n",
    "        self.num_agents = num_agents\n",
    "        self.grid_size = grid_size\n",
    "        self.cell_size = renderer.cell_size\n",
    "        self.margin = MARGIN_SIZE\n",
    "        self.inner_grid_size = self.grid_size - self.margin * 2\n",
    "        base_coords = (self.margin + 1, self.grid_size // 2 - STATION_SIZE // 2)\n",
    "        self.base_positions: Set[Tuple[int, int]] = {\n",
    "            (base_coords[0] + i, base_coords[1] + j)\n",
    "            for i in range(STATION_SIZE)\n",
    "            for j in range(STATION_SIZE)\n",
    "        }\n",
    "        self.agents: List[Agent] = [\n",
    "            Agent(self, name=f'agent_{i}') for i in range(self.num_agents)\n",
    "        ]\n",
    "        self.done_status = np.zeros(COUNT_TARGETS, dtype=int)\n",
    "        self.start_time: Optional[float] = None\n",
    "        self.total_reward: float = 0.0\n",
    "        self.step_reward: float = 0.0\n",
    "        self.target_positions: List[Tuple[int, int]] = []\n",
    "        self.obstacle_positions: Set[Tuple[int, int]] = set()\n",
    "        self.current_map: np.ndarray = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "        self.step_count: int = 0\n",
    "        self.obstacle_icons: List[pygame.Surface] = []\n",
    "        self.renderer = renderer\n",
    "        self.pathfinder = AStarPathfinder()\n",
    "        self.occupied_positions: Set[Tuple[int, int]] = set()\n",
    "        # Дополнительная статистика\n",
    "        self.detected_flowers: int = 0\n",
    "        self.sprayed_flowers: int = 0\n",
    "        self.total_points: int = 0\n",
    "\n",
    "    def reset_objects_positions(self) -> None:\n",
    "        \"\"\"Сбрасывает позиции объектов в сценарии.\"\"\"\n",
    "        if PLACEMENT_MODE == 'random':\n",
    "            self._randomize_positions()\n",
    "        elif PLACEMENT_MODE == 'fixed':\n",
    "            self._fixed_positions()\n",
    "        else:\n",
    "            logging.error(\"Invalid PLACEMENT_MODE. Choose 'random' or 'fixed'.\")\n",
    "            raise ValueError(\"Invalid PLACEMENT_MODE. Choose 'random' or 'fixed'.\")\n",
    "\n",
    "    def _randomize_positions(self) -> None:\n",
    "        \"\"\"Генерирует случайные позиции объектов.\"\"\"\n",
    "        try:\n",
    "            unavailable_positions = set(self.base_positions)\n",
    "            self.target_positions = self._get_objects_positions(unavailable_positions, COUNT_TARGETS)\n",
    "            unavailable_positions.update(self.target_positions)\n",
    "            self.obstacle_positions = set(self._get_objects_positions(unavailable_positions, COUNT_OBSTACLES))\n",
    "            # Проверка на окружение целей препятствиями с использованием множеств\n",
    "            while any(self._is_surrounded_by_obstacles(target) for target in self.target_positions):\n",
    "                self.obstacle_positions = set(self._get_objects_positions(unavailable_positions, COUNT_OBSTACLES))\n",
    "            logging.info(\"Случайные позиции объектов успешно сгенерированы\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _randomize_positions: {e}\")\n",
    "\n",
    "    def _fixed_positions(self) -> None:\n",
    "        \"\"\"Устанавливает фиксированные позиции объектов.\"\"\"\n",
    "        try:\n",
    "            # Проверка, что фиксированные позиции находятся в пределах grid_size\n",
    "            self.target_positions = [pos for pos in FIXED_TARGET_POSITIONS if pos[0] < self.grid_size and pos[1] < self.grid_size]\n",
    "            self.obstacle_positions = set([pos for pos in FIXED_OBSTACLE_POSITIONS if pos[0] < self.grid_size and pos[1] < self.grid_size])\n",
    "            logging.info(\"Фиксированные позиции объектов установлены\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _fixed_positions: {e}\")\n",
    "\n",
    "    def _is_surrounded_by_obstacles(self, target_position: Tuple[int, int]) -> bool:\n",
    "        \"\"\"\n",
    "        Проверяет, окружена ли цель препятствиями.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            x, y = target_position\n",
    "            step = 1\n",
    "            surrounding_positions = {\n",
    "                (x - step, y), (x + step, y), (x, y - step), (x, y + step)\n",
    "            }\n",
    "\n",
    "            obstacle_count = len(surrounding_positions & self.obstacle_positions)\n",
    "            return obstacle_count == 4\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _is_surrounded_by_obstacles: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _get_available_positions(self, unavailable: Set[Tuple[int, int]]) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Получает доступные позиции для размещения объектов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_positions = [\n",
    "                (i, j) for i in range(self.margin, self.inner_grid_size + 1)\n",
    "                for j in range(self.margin, self.inner_grid_size + 1)\n",
    "            ]\n",
    "            available = [pos for pos in all_positions if pos not in unavailable]\n",
    "            return available\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _get_available_positions: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _get_objects_positions(\n",
    "        self,\n",
    "        unavailable: Set[Tuple[int, int]],\n",
    "        size: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Получает список позиций объектов с учётом недоступных позиций.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            available_positions = self._get_available_positions(unavailable)\n",
    "            if len(available_positions) < size:\n",
    "                raise ValueError(\"Недостаточно доступных позиций для размещения объектов.\")\n",
    "            selected_positions = random.sample(available_positions, size)\n",
    "            return selected_positions\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _get_objects_positions: {e}\")\n",
    "            return []\n",
    "\n",
    "    # def get_remaining_targets(self) -> List[Tuple[int, int]]:\n",
    "    #     \"\"\"Возвращает список оставшихся целей для опрыскивания.\"\"\"\n",
    "    #     # Удаляем предоставление полного списка целей\n",
    "    #     # Теперь агенты используют свои собственные известные цели\n",
    "    #     logging.warning(\"Метод get_remaining_targets больше не используется агентами.\")\n",
    "    #     return []  # Возвращаем пустой список или полностью удаляем этот метод\n",
    "\n",
    "    def reset(self) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Сбрасывает сценарий в исходное состояние.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.reset_objects_positions()\n",
    "            self.start_time = time.time()\n",
    "            self.step_count = 1\n",
    "            self.done_status = np.zeros(COUNT_TARGETS, dtype=int)\n",
    "            self.total_reward = 0.0\n",
    "            self.step_reward = 0.0\n",
    "            self.current_map = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "            self.obstacle_icons = load_obstacles(OBSTACLES_DIR, self.cell_size, COUNT_OBSTACLES)\n",
    "            for agent in self.agents:\n",
    "                agent.reset()\n",
    "            obs = self.get_observation()\n",
    "            logging.info(\"Перезагрузка среды\")\n",
    "            return obs, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе reset: {e}\")\n",
    "            return {}, {}\n",
    "\n",
    "    def get_observation(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Получает объединённые наблюдения от всех агентов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            combined_coords = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "            combined_energy = []\n",
    "            combined_tank = []\n",
    "            for agent in self.agents:\n",
    "                obs = agent.get_observation()\n",
    "                combined_coords = np.maximum(combined_coords, obs['coords'])\n",
    "                combined_energy.append(obs['energy'])\n",
    "                combined_tank.append(obs['tank'])\n",
    "\n",
    "            self.current_map = np.maximum(self.current_map, combined_coords)\n",
    "\n",
    "            # Обновление занятых позиций\n",
    "            self.env_update_occupied_positions()\n",
    "\n",
    "            obs = {\n",
    "                'pos': np.array([agent.position for agent in self.agents]),\n",
    "                'coords': self.current_map,\n",
    "                'energy': combined_energy,\n",
    "                'tank': combined_tank\n",
    "            }\n",
    "            return obs\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_observation: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def get_explored_unsprayed_cells(self) -> Set[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Возвращает множество координат разведанных клеток, содержащих непролитыми цветками.\n",
    "        \n",
    "        Разведанные клетки — это те, которые были помечены как VIEWED или VISITED.\n",
    "        Непролитые цветки — это цели с done_status == 0.\n",
    "        \n",
    "        Returns:\n",
    "            Set[Tuple[int, int]]: Множество координат (x, y).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            explored_unsprayed = set()\n",
    "            for idx, target_pos in enumerate(self.target_positions):\n",
    "                if self.done_status[idx] == 0:\n",
    "                    x, y = target_pos\n",
    "                    point_status = self.current_map[x, y, 0]\n",
    "                    object_status = self.current_map[x, y, 1]\n",
    "                    \n",
    "                    # Проверяем, что клетка разведана и содержит цель\n",
    "                    if (point_status in {PointStatus.VIEWED.value, PointStatus.VISITED.value} and\n",
    "                        object_status == ObjectStatus.TARGET.value):\n",
    "                        explored_unsprayed.add(target_pos)\n",
    "            \n",
    "            logging.debug(f\"Разведанные и непролитые клетки: {explored_unsprayed}\")\n",
    "            return explored_unsprayed\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_explored_unsprayed_cells: {e}\")\n",
    "            return set()\n",
    "    \n",
    "    def env_update_occupied_positions(self):\n",
    "        \"\"\"Обновляет множество занятых позиций для быстрого доступа.\"\"\"\n",
    "        self.occupied_positions = {agent.position for agent in self.agents if agent.position is not None}\n",
    "\n",
    "    def step(self) -> Tuple[Dict[str, Any], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Выполняет один шаг сценария.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Шаг: {self.step_count}\")\n",
    "            obs = self.get_observation()\n",
    "            \n",
    "            self.step_reward = 0.0\n",
    "\n",
    "            # Пакетная обработка действий агентов\n",
    "            actions = []\n",
    "            desired_positions: Dict[Agent, Tuple[int, int]] = {}\n",
    "            for agent in self.agents:\n",
    "                new_position, agent_reward, terminated, truncated, info = agent.take_action()\n",
    "                desired_positions[agent] = new_position\n",
    "                actions.append((agent, new_position, agent_reward))\n",
    "\n",
    "            # Обработка действий агентов\n",
    "            # Проверяем на наложение позиций\n",
    "            position_counts: Dict[Tuple[int, int], int] = {}\n",
    "            for _, pos, _ in actions:\n",
    "                if pos in position_counts:\n",
    "                    position_counts[pos] += 1\n",
    "                else:\n",
    "                    position_counts[pos] = 1\n",
    "\n",
    "            for agent, new_position, agent_reward in actions:\n",
    "                if position_counts[new_position] > 1:\n",
    "                    # Если несколько агентов пытаются попасть в одну клетку, предотвращаем движение\n",
    "                    logging.warning(f\"Дрон {agent.name} не может переместиться на занятую клетку {new_position}\")\n",
    "                    new_position = agent.position  # Остаётся на месте\n",
    "                    agent_reward -= PENALTY_CRASH\n",
    "                else:\n",
    "                    value_position = obs['coords'][new_position[0]][new_position[1]]\n",
    "                    if value_position[0] in (PointStatus.EMPTY.value, PointStatus.VIEWED.value):\n",
    "                        if value_position[1] != ObjectStatus.TARGET.value:\n",
    "                            self.step_reward += REWARD_EXPLORE\n",
    "                            self.detected_flowers += 1  # Увеличиваем счетчик обнаруженных цветков\n",
    "                            self.current_map[new_position[0], new_position[1], 0] = PointStatus.VISITED.value\n",
    "                            logging.info(\n",
    "                                f\"{agent.name} исследовал новую клетку {new_position} + {REWARD_EXPLORE}\"\n",
    "                            )\n",
    "                        #self.current_map[new_position[0], new_position[1], 0] = PointStatus.VISITED.value\n",
    "                    agent.position = new_position\n",
    "                    self.step_reward += agent_reward\n",
    "\n",
    "            # Обновляем общие очки\n",
    "            self.total_reward += self.step_reward\n",
    "\n",
    "            # Проверяем условия завершения игры\n",
    "            reward, terminated, truncated, info = self._check_termination_conditions()\n",
    "            self.step_count += 1\n",
    "            logging.info(\n",
    "                f\"Награда: {self.total_reward}, \"\n",
    "                f\"Завершено: {terminated}, \"\n",
    "                f\"Прервано: {truncated}\"\n",
    "            )\n",
    "\n",
    "            return obs, reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе step: {e}\")\n",
    "            return {}, 0, False, False, {}\n",
    "\n",
    "    def _check_termination_conditions(self) -> Tuple[int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Проверяет условия завершения игры: количество шагов и обработка всех целей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            total_reward = 0\n",
    "\n",
    "            if self.step_count >= MAX_STEPS_GAME:\n",
    "                logging.info(\"Достигнуто максимальное количество шагов\")\n",
    "                truncated = True\n",
    "                total_reward = 0\n",
    "\n",
    "            elif np.all(self.done_status == 1):\n",
    "                terminated = True\n",
    "                logging.info(\"Все растения опрысканы\")\n",
    "                for agent in self.agents:\n",
    "                    agent.position = random.choice(list(self.base_positions))\n",
    "                logging.info(\"Агенты вернулись на базу\")\n",
    "\n",
    "                if self.step_count <= MIN_GAME_STEPS:\n",
    "                    total_reward = self.total_reward + REWARD_COMPLETION * 3\n",
    "                    logging.info(\n",
    "                        f\"Увеличенная награда: {total_reward} за шагов меньше, чем {MIN_GAME_STEPS}\"\n",
    "                    )\n",
    "                else:\n",
    "                    total_reward = self.total_reward + REWARD_COMPLETION\n",
    "                    logging.info(f\"Награда: {total_reward}\")\n",
    "                self.total_reward = 0.0\n",
    "            else:\n",
    "                total_reward = 0\n",
    "\n",
    "            return total_reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _check_termination_conditions: {e}\")\n",
    "            return 0, False, False, {}\n",
    "\n",
    "    def check_crash(\n",
    "        self,\n",
    "        obs: Dict[str, Any],\n",
    "        agent: Agent,\n",
    "        new_position: Tuple[int, int]\n",
    "    ) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Проверяет на столкновение агентов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            collision_count = 0\n",
    "            # Использование множеств для быстрого поиска\n",
    "            if new_position in self.occupied_positions:\n",
    "                collision_count += 1\n",
    "            if collision_count > 0:\n",
    "                self.total_reward -= PENALTY_CRASH * collision_count\n",
    "                logging.warning(\n",
    "                    f\"Столкновение {collision_count} агентов в позиции {new_position}\"\n",
    "                )\n",
    "                new_position = agent.position\n",
    "            return new_position\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе check_crash: {e}\")\n",
    "            return agent.position\n",
    "\n",
    "    def render(self) -> None:\n",
    "        \"\"\"Отображает текущее состояние игры с оптимизациями.\"\"\"\n",
    "        try:\n",
    "            rects_to_update = []\n",
    "\n",
    "            # Отрисовка фона\n",
    "            self.renderer.screen.blit(self.renderer.base_icons['field_bg'], (0, 0))\n",
    "            self.renderer.screen.blit(self.renderer.base_icons['field'], (0, 0))\n",
    "            rects_to_update.extend([\n",
    "                self.renderer.base_icons['field_bg'].get_rect(),\n",
    "                self.renderer.base_icons['field'].get_rect()\n",
    "            ])\n",
    "\n",
    "            # Отрисовка сетки\n",
    "            self.renderer.draw_grid()\n",
    "\n",
    "            # Отрисовка базы\n",
    "            rect = self.renderer.draw_base(next(iter(self.base_positions)))\n",
    "            rects_to_update.append(rect)\n",
    "\n",
    "            # Отрисовка целей и препятствий\n",
    "            rects_to_update.extend(self.renderer.draw_objects(\n",
    "                target_positions=self.target_positions,\n",
    "                done_status=self.done_status,\n",
    "                obstacle_positions=self.obstacle_positions,\n",
    "                current_map=self.current_map,\n",
    "                obstacle_icons=self.obstacle_icons\n",
    "            ))\n",
    "\n",
    "            # Накладываем оверлей на неизведанные области\n",
    "            rects_to_update.extend(self.renderer.draw_overlay(self.current_map))\n",
    "\n",
    "            # Отрисовка агентов\n",
    "            rects_to_update.extend(self.renderer.draw_agents(self.agents))\n",
    "\n",
    "            # Отрисовка панели статуса\n",
    "            rects_to_update.extend(self.renderer.draw_status_panel(\n",
    "                agents=self.agents,\n",
    "                total_steps=self.step_count,\n",
    "                total_points=int(self.total_reward),\n",
    "                detected_flowers=self.detected_flowers,\n",
    "                sprayed_flowers=self.sprayed_flowers\n",
    "            ))\n",
    "\n",
    "            # Обновление только изменённых областей\n",
    "            pygame.display.update(rects_to_update)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе render: {e}\")\n",
    "\n",
    "    def render_full_screen(self) -> None:\n",
    "        \"\"\"\n",
    "        Рендерит начальное сообщение и настраивает экран.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.renderer.render_message(\n",
    "                \"Начало выполнения сценария\\n\\n\\n\" +\n",
    "                f\"Гиперпараметры модели:\\n\\n\"\n",
    "                f\"Темп: {LEARNING_RATE}\\n\"\n",
    "                f\"Гамма: {GAMMA}\\n\"\n",
    "                f\"Диапазон обрезки: {CLIP_RANGE}\\n\"\n",
    "                f\"Длина эпизода: {N_STEPS}\\n\"\n",
    "                f\"Энтропия: {COEF}\\n\"\n",
    "                f\"Баланс ценности: {VF_COEF}\\n\"\n",
    "                f\"Эпох: {N_EPOCHS}\\n\"\n",
    "                f\"Размер батча: {BATCH_SIZE}\\n\"\n",
    "            )\n",
    "            pygame.display.set_caption(\"OS SWARM OF DRONES\")\n",
    "            logging.info(\"Начало выполнения сценария\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе render_full_screen: {e}\")\n",
    "\n",
    "class PygameHandler:\n",
    "    \"\"\"\n",
    "    Класс для централизованного управления pygame и основным циклом игры с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.total_steps: int = 0\n",
    "        self.total_points: int = 0\n",
    "        self.detected_flowers: int = 0\n",
    "        self.sprayed_flowers: int = 0\n",
    "        # Создаем менеджер Pygame с новым размером экрана\n",
    "        self.pygame_manager = PygameManager(width=SCREEN_SIZE + STATUS_PANEL_WIDTH, height=SCREEN_SIZE + BAR_HEIGHT)\n",
    "        self.pygame_manager.create_screen()\n",
    "        self.renderer: Optional[Renderer] = None  # Инициализируем позже\n",
    "        self.scenario: Optional[SprayingScenario] = None\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Запускает основной цикл игры.\"\"\"\n",
    "        try:\n",
    "            num_agents, grid_size, selected = self.input_screen()\n",
    "            cell_size = SCREEN_SIZE // grid_size\n",
    "\n",
    "            # Теперь инициализируем Renderer с пользовательскими параметрами\n",
    "            self.renderer = Renderer(\n",
    "                pygame_manager=self.pygame_manager,\n",
    "                grid_size=grid_size,\n",
    "                cell_size=cell_size,\n",
    "                status_panel_width=STATUS_PANEL_WIDTH\n",
    "            )\n",
    "\n",
    "            # Инициализируем сценарий с актуальными параметрами\n",
    "            self.scenario = SprayingScenario(num_agents, grid_size, self.renderer)\n",
    "            self.scenario.reset_objects_positions()\n",
    "            self.scenario.render_full_screen()\n",
    "\n",
    "            clock = pygame.time.Clock()\n",
    "            pygame.display.set_caption(\"Pesticide Spraying Scenario\")\n",
    "\n",
    "            obs, info = self.scenario.reset()\n",
    "            self.total_steps = 0\n",
    "            self.total_points = 0\n",
    "            self.detected_flowers = 0\n",
    "            self.sprayed_flowers = 0\n",
    "\n",
    "            while True:\n",
    "                self.handle_events()\n",
    "\n",
    "                # Выполняем шаг сценария\n",
    "                obs, reward, terminated, truncated, info = self.scenario.step()\n",
    "                self.total_steps = self.scenario.step_count\n",
    "                self.total_points = int(self.scenario.total_reward)\n",
    "                self.sprayed_flowers = self.scenario.sprayed_flowers\n",
    "                self.detected_flowers = self.scenario.detected_flowers\n",
    "                self.scenario.render()\n",
    "                self.renderer.draw_status_panel(\n",
    "                    agents=self.scenario.agents,\n",
    "                    total_steps=self.total_steps,\n",
    "                    total_points=self.total_points,\n",
    "                    detected_flowers=self.detected_flowers,\n",
    "                    sprayed_flowers=self.sprayed_flowers\n",
    "                )\n",
    "                pygame.display.flip()\n",
    "\n",
    "                if truncated:\n",
    "                    obs, info = self.scenario.reset()\n",
    "                    self.renderer.render_message(\"Новая миссия\")\n",
    "                    pygame.time.wait(5000)\n",
    "                    self.total_steps = 0\n",
    "                    self.total_points = 0\n",
    "                    self.detected_flowers = 0\n",
    "                    self.sprayed_flowers = 0\n",
    "\n",
    "                if terminated:\n",
    "                    message = f\"Конец миссии, награда: {int(reward)}, шагов: {self.total_steps}\"\n",
    "                    self.renderer.render_message(message)\n",
    "                    pygame.display.flip()\n",
    "                    pygame.time.wait(5000)\n",
    "                    break\n",
    "\n",
    "                clock.tick(60)  # Поддерживаем частоту кадров\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Прервано пользователем\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Произошла ошибка в основном цикле: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.pygame_manager.quit()\n",
    "\n",
    "    def handle_events(self) -> None:\n",
    "        \"\"\"Обрабатывает события pygame.\"\"\"\n",
    "        try:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при обработке событий: {e}\")\n",
    "\n",
    "    def input_screen(self) -> Tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        Отображает окно ввода для выбора количества агентов, размера поля и сценария.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Используем уже созданный screen из PygameManager\n",
    "            screen = self.pygame_manager.screen\n",
    "            font = pygame.font.Font(None, 36)\n",
    "            small_font = pygame.font.Font(None, 24)\n",
    "            clock = pygame.time.Clock()\n",
    "\n",
    "            inputs = [\n",
    "                \"Введите количество агентов:\",\n",
    "                \"Введите размер поля (минимум):\",\n",
    "                \"Выберите сценарий (1 - spraying):\"\n",
    "            ]\n",
    "            input_boxes = [pygame.Rect(150, 150 + i * 80, 300, 40) for i in range(len(inputs))]\n",
    "            input_values = [\"\", \"\", \"\"]\n",
    "\n",
    "            active_box = 0\n",
    "            finished = False\n",
    "\n",
    "            while not finished:\n",
    "                screen.fill(GRAY)\n",
    "                grid_size_min = 0  # Минимальный размер поля, обновляется динамически\n",
    "                try:\n",
    "                    num_agents = int(input_values[0]) if input_values[0].isdigit() else NUM_AGENTS\n",
    "                    grid_size_min = ceil(\n",
    "                        (COUNT_TARGETS + COUNT_OBSTACLES + int(num_agents)) ** 0.5\n",
    "                    ) + STATION_SIZE\n",
    "                except ValueError:\n",
    "                    grid_size_min = 0  # Если ввод некорректный, не рассчитываем\n",
    "\n",
    "                for event in pygame.event.get():\n",
    "                    if event.type == pygame.QUIT:\n",
    "                        pygame.quit()\n",
    "                        sys.exit()\n",
    "                    if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                        for i, box in enumerate(input_boxes):\n",
    "                            if box.collidepoint(event.pos):\n",
    "                                active_box = i\n",
    "                    if event.type == pygame.KEYDOWN:\n",
    "                        if active_box < len(inputs):\n",
    "                            if event.key == pygame.K_BACKSPACE:\n",
    "                                input_values[active_box] = input_values[active_box][:-1]\n",
    "                            elif event.key == pygame.K_RETURN:\n",
    "                                active_box += 1\n",
    "                                if active_box >= len(inputs):\n",
    "                                    finished = True\n",
    "                            else:\n",
    "                                input_values[active_box] += event.unicode\n",
    "\n",
    "                # Отрисовка подсказок и полей ввода\n",
    "                for i, text in enumerate(inputs):\n",
    "                    # Отображаем текст с выравниванием\n",
    "                    if i == 1 and grid_size_min > 0:\n",
    "                        display_text = f\"Введите размер поля (минимум: {grid_size_min}):\"\n",
    "                    else:\n",
    "                        display_text = text\n",
    "\n",
    "                    render_text(\n",
    "                        screen, display_text, small_font, (200, 200, 200), 150,\n",
    "                        120 + i * 80\n",
    "                    )\n",
    "                    color = WHITE if i == active_box else BLACK\n",
    "                    pygame.draw.rect(screen, color, input_boxes[i], 2)\n",
    "                    render_text(\n",
    "                        screen, input_values[i], font, BLACK, input_boxes[i].x + 5,\n",
    "                        input_boxes[i].y + 5\n",
    "                    )\n",
    "\n",
    "                pygame.display.flip()\n",
    "                clock.tick(30)\n",
    "\n",
    "            # Преобразование и проверка введённых данных\n",
    "            try:\n",
    "                num_agents = int(input_values[0]) if input_values[0] else NUM_AGENTS\n",
    "                grid_size = int(input_values[1]) if input_values[1] else GRID_SIZE\n",
    "                if grid_size < grid_size_min:\n",
    "                    raise ValueError(f\"Размер поля должен быть больше, чем {grid_size_min}\")\n",
    "                selected_scenario = int(input_values[2]) if input_values[2] else 1\n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Ошибка ввода: {e}\")\n",
    "                # Используем значения по умолчанию, так как renderer еще не инициализирован\n",
    "                pygame.display.set_caption(\"Ошибка ввода\")\n",
    "                self.pygame_manager.screen.fill(GRAY)\n",
    "                message = f\"Ошибка ввода:\\n{e}\"\n",
    "                font = pygame.font.SysFont('Arial', 36)\n",
    "                lines = message.split('\\n')\n",
    "                total_height = 0\n",
    "                for i, line in enumerate(lines):\n",
    "                    text_surface = font.render(line, True, RED)\n",
    "                    text_width, text_height = font.size(line)\n",
    "                    x = (SCREEN_SIZE + STATUS_PANEL_WIDTH - text_width) // 2\n",
    "                    y = (SCREEN_SIZE + BAR_HEIGHT - len(lines) * text_height) // 2 + total_height\n",
    "                    self.pygame_manager.screen.blit(text_surface, (x, y))\n",
    "                    total_height += text_height + 5\n",
    "                pygame.display.flip()\n",
    "                pygame.time.wait(3000)\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "\n",
    "            return num_agents, grid_size, selected_scenario\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе input_screen: {e}\")\n",
    "            # Показать сообщение об ошибке, если Renderer не инициализирован\n",
    "            if self.renderer:\n",
    "                self.renderer.render_message(\"Ошибка ввода. Использованы значения по умолчанию.\")\n",
    "                pygame.time.wait(3000)\n",
    "            pygame.quit()\n",
    "            return NUM_AGENTS, GRID_SIZE, 1\n",
    "\n",
    "# =============================================================================\n",
    "# Главная функция\n",
    "# =============================================================================\n",
    "\n",
    "def run() -> None:\n",
    "    \"\"\"\n",
    "    Главная функция для запуска сценария.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pygame_handler = PygameHandler()\n",
    "        pygame_handler.run()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при запуске сценария: {e}\")\n",
    "        pygame_handler.pygame_manager.quit()\n",
    "        sys.exit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67167b4-40f5-4c86-8cbe-55830c9ff7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e63377-24be-4b5b-bfbf-eec2260eba58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
