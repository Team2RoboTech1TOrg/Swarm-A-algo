{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfc74e29-318f-4019-8931-f33d5458dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Файл one.py\n",
    "\n",
    "# =============================================================================\n",
    "# Импорты\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import logging\n",
    "import heapq\n",
    "import enum\n",
    "from math import ceil\n",
    "from collections import deque\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, List, Tuple, Optional, Dict, Set\n",
    "from functools import lru_cache\n",
    "from threading import Thread\n",
    "\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "# =============================================================================\n",
    "# Константы\n",
    "# =============================================================================\n",
    "\n",
    "# ----------------------\n",
    "# Параметры модели\n",
    "# ----------------------\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.99\n",
    "CLIP_RANGE = 0.2\n",
    "N_STEPS = 4096\n",
    "COEF = 0.001\n",
    "VF_COEF = 0.6\n",
    "CLIP_RANGE_VF = 0.2\n",
    "N_EPOCHS = 1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# ----------------------\n",
    "# Параметры экрана и сетки\n",
    "# ----------------------\n",
    "SCREEN_SIZE = 900\n",
    "BAR_HEIGHT = int(SCREEN_SIZE * 0.13)\n",
    "GRID_SIZE = 30\n",
    "MARGIN_SIZE = 1\n",
    "\n",
    "# ----------------------\n",
    "# Параметры игры\n",
    "# ----------------------\n",
    "NUM_AGENTS = 3\n",
    "COUNT_TARGETS = 100  # ceil((GRID_SIZE ** 2) * 0.4)\n",
    "COUNT_OBSTACLES = 12  # ceil((GRID_SIZE ** 2) * 0.03)\n",
    "STATION_SIZE = 2\n",
    "MAX_STEPS_GAME = (GRID_SIZE ** 2) * 10\n",
    "VIEW_RANGE = 1  # Область зрения 3x3\n",
    "ON_TARGET_CONSUMPTION = 10  # Расход\n",
    "TANK_CAPACITY = COUNT_TARGETS * ON_TARGET_CONSUMPTION  # Максимальный запас\n",
    "ENERGY_CAPACITY = 1000  # Максимальный запас энергии\n",
    "ENERGY_CONSUMPTION_MOVE = 1\n",
    "ENERGY_CONSUMPTION_DONE = 2\n",
    "COUNT_ACTIONS = 4\n",
    "MIN_GAME_STEPS = (GRID_SIZE * GRID_SIZE // NUM_AGENTS) * 2\n",
    "\n",
    "# ----------------------\n",
    "# Награды\n",
    "# ----------------------\n",
    "REWARD_EXPLORE = 5  # Вознаграждение за исследование новых клеток\n",
    "REWARD_DONE = 3\n",
    "REWARD_COMPLETION = (REWARD_DONE * COUNT_TARGETS) * 10\n",
    "PENALTY_LOOP = 1\n",
    "PENALTY_OUT_FIELD = 2\n",
    "PENALTY_OBSTACLE = 2\n",
    "PENALTY_CRASH = 3\n",
    "\n",
    "# ----------------------\n",
    "# Позиции\n",
    "# ----------------------\n",
    "PLACEMENT_MODE = 'random'\n",
    "\n",
    "FIXED_TARGET_POSITIONS = [\n",
    "    (2, 2), (2, 8), (4, 3), (4, 7), (6, 2),\n",
    "    (6, 8), (8, 4), (8, 6), (3, 5), (7, 5)\n",
    "]\n",
    "\n",
    "FIXED_OBSTACLE_POSITIONS = [\n",
    "    (1, 1), (1, 9), (3, 3), (7, 7), (9, 5)\n",
    "]\n",
    "\n",
    "# ----------------------\n",
    "# Цвета\n",
    "# ----------------------\n",
    "WHITE = (200, 200, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "GREEN = (34, 139, 34)\n",
    "BLUE = (0, 0, 255)\n",
    "RED = (255, 69, 0)\n",
    "GRAY = (30, 30, 30)\n",
    "\n",
    "# ----------------------\n",
    "# Изображения\n",
    "# ----------------------\n",
    "AGENT_IMG = \"images/drone.png\"\n",
    "TARGET_IMG = \"images/bad_plant.png\"\n",
    "DONE_TARGET_IMG = \"images/healthy_plant.png\"\n",
    "OBSTACLES_DIR = \"./images/obstacles\"\n",
    "STATION_IMG = \"images/robdocst.png\"\n",
    "FIELD_IMG = \"images/field.png\"\n",
    "FIELD_BACKGROUND_IMG = \"images/forest.jpg\"\n",
    "\n",
    "# ----------------------\n",
    "# Логирование\n",
    "# ----------------------\n",
    "LOG_DIR = \"./logs\"\n",
    "LOG_FILE = os.path.join(LOG_DIR, 'logging.log')\n",
    "\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILE,\n",
    "    level=logging.INFO,  # Уровень логирования изменен на INFO для более подробного отслеживания\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Перечисления\n",
    "# =============================================================================\n",
    "\n",
    "class PointStatus(enum.Enum):\n",
    "    \"\"\"Статусы точек на карте.\"\"\"\n",
    "    EMPTY = 0\n",
    "    VIEWED = 1\n",
    "    VISITED = 2\n",
    "\n",
    "class ObjectStatus(enum.Enum):\n",
    "    \"\"\"Статусы объектов на карте.\"\"\"\n",
    "    EMPTY = 0\n",
    "    OBSTACLE = 1\n",
    "    TARGET = 2\n",
    "\n",
    "# =============================================================================\n",
    "# Утилиты\n",
    "# =============================================================================\n",
    "\n",
    "def load_image(filename: str, cell_size: int) -> pygame.Surface:\n",
    "    \"\"\"\n",
    "    Загружает и масштабирует изображение для объектов.\n",
    "    Используется многопоточность для предварительной загрузки изображений.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        image = pygame.image.load(filename)\n",
    "        return pygame.transform.scale(image, (cell_size, cell_size))\n",
    "    except pygame.error as e:\n",
    "        logging.error(f\"Не удалось загрузить изображение {filename}: {e}\")\n",
    "        return pygame.Surface((cell_size, cell_size))\n",
    "\n",
    "def load_obstacles(directory: str, cell_size: int, count: int) -> List[pygame.Surface]:\n",
    "    \"\"\"\n",
    "    Загружает случайные изображения препятствий из указанного каталога.\n",
    "    Использует многопоточность для ускорения загрузки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        all_files = [\n",
    "            os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "        ]\n",
    "        selected_files = random.sample(all_files, min(count, len(all_files)))\n",
    "        return [load_image(f, cell_size) for f in selected_files]\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка загрузки препятствий из {directory}: {e}\")\n",
    "        return []\n",
    "\n",
    "def render_text(\n",
    "    screen: pygame.Surface,\n",
    "    text: Any,\n",
    "    font: pygame.font.Font,\n",
    "    color: Tuple[int, int, int],\n",
    "    x: int,\n",
    "    y: int\n",
    ") -> pygame.Rect:\n",
    "    \"\"\"\n",
    "    Отображает текст на экране pygame и возвращает область отрисовки.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text_surface = font.render(str(text), True, color)\n",
    "        rect = text_surface.get_rect(topleft=(x, y))\n",
    "        screen.blit(text_surface, rect)\n",
    "        return rect\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при отображении текста: {e}\")\n",
    "        return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "# =============================================================================\n",
    "# Менеджер Pygame\n",
    "# =============================================================================\n",
    "\n",
    "class PygameManager:\n",
    "    \"\"\"\n",
    "    Класс для централизованного управления инициализацией и ресурсами pygame.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "        self.screen = None\n",
    "\n",
    "    def create_screen(self, width: int, height: int) -> None:\n",
    "        \"\"\"\n",
    "        Создает окно pygame.\n",
    "        \"\"\"\n",
    "        if self.screen is None:\n",
    "            self.screen = pygame.display.set_mode((width, height))\n",
    "            logging.info(f\"Создано окно pygame размером {width}x{height}\")\n",
    "\n",
    "    def quit(self) -> None:\n",
    "        \"\"\"Завершает работу pygame.\"\"\"\n",
    "        pygame.quit()\n",
    "        logging.info(\"pygame завершил работу\")\n",
    "\n",
    "# =============================================================================\n",
    "# Классы\n",
    "# =============================================================================\n",
    "\n",
    "class AStarPathfinder:\n",
    "    \"\"\"\n",
    "    Класс для реализации алгоритма A* поиска пути с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.cache: Dict[Tuple[Tuple[int, int], Tuple[Tuple[int, int], ...]], Optional[List[Tuple[int, int]]]] = {}\n",
    "\n",
    "    @staticmethod\n",
    "    def heuristic(a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "        \"\"\"Манхэттенское расстояние между двумя точками.\"\"\"\n",
    "        return abs(a[0] - b[0]) + abs(a[1] - b[1])\n",
    "\n",
    "    def find_path(\n",
    "        self,\n",
    "        start: Tuple[int, int],\n",
    "        goals: Set[Tuple[int, int]],\n",
    "        known_map: np.ndarray,\n",
    "        grid_size: int,\n",
    "        occupied_positions: Set[Tuple[int, int]]\n",
    "    ) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь от старта до одной из целей с использованием A* и кэшированием.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Сортировка целей по эвристике для более быстрой остановки\n",
    "            sorted_goals = sorted(goals, key=lambda goal: self.heuristic(start, goal))\n",
    "            \n",
    "            if not sorted_goals:\n",
    "                logging.warning(\"No goals provided for pathfinding\")\n",
    "                return None\n",
    "\n",
    "            goals_tuple = tuple(sorted_goals)\n",
    "\n",
    "            cache_key = (start, goals_tuple)\n",
    "            if cache_key in self.cache:\n",
    "                return self.cache[cache_key]\n",
    "\n",
    "            open_heap = []\n",
    "            heapq.heappush(open_heap, (0, start))\n",
    "            came_from: Dict[Tuple[int, int], Tuple[int, int]] = {}\n",
    "            g_score = {start: 0}\n",
    "            f_score = {start: self.heuristic(start, sorted_goals[0])}\n",
    "\n",
    "            open_set = {start}\n",
    "            closed_set = set()\n",
    "\n",
    "            while open_heap:\n",
    "                current_f, current = heapq.heappop(open_heap)\n",
    "                open_set.remove(current)\n",
    "\n",
    "                if current in goals:\n",
    "                    # Восстанавливаем путь\n",
    "                    path = []\n",
    "                    while current in came_from:\n",
    "                        path.append(current)\n",
    "                        current = came_from[current]\n",
    "                    path.append(start)\n",
    "                    path.reverse()\n",
    "                    self.cache[cache_key] = path\n",
    "                    logging.debug(f\"Найден путь: {path}\")\n",
    "                    return path\n",
    "\n",
    "                closed_set.add(current)\n",
    "\n",
    "                neighbors = [\n",
    "                    (current[0] + dx, current[1] + dy)\n",
    "                    for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "                ]\n",
    "\n",
    "                for neighbor in neighbors:\n",
    "                    if not (0 <= neighbor[0] < grid_size and 0 <= neighbor[1] < grid_size):\n",
    "                        continue\n",
    "                    if known_map[neighbor[0]][neighbor[1]][1] == ObjectStatus.OBSTACLE.value:\n",
    "                        continue\n",
    "                    if neighbor in occupied_positions:\n",
    "                        continue\n",
    "                    if neighbor in closed_set:\n",
    "                        continue\n",
    "\n",
    "                    tentative_g_score = g_score[current] + 1\n",
    "\n",
    "                    if tentative_g_score < g_score.get(neighbor, float('inf')):\n",
    "                        came_from[neighbor] = current\n",
    "                        g_score[neighbor] = tentative_g_score\n",
    "                        # Улучшенная эвристика: сортировка целей позволяет использовать минимальную эвристику\n",
    "                        f_score[neighbor] = tentative_g_score + self.heuristic(neighbor, sorted_goals[0])\n",
    "                        if neighbor not in open_set:\n",
    "                            heapq.heappush(open_heap, (f_score[neighbor], neighbor))\n",
    "                            open_set.add(neighbor)\n",
    "\n",
    "            logging.debug(\"Путь не найден\")\n",
    "            self.cache[cache_key] = None\n",
    "            return None  # Путь не найден\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в AStarPathfinder.find_path: {e}\")\n",
    "            return None\n",
    "\n",
    "class Renderer:\n",
    "    \"\"\"\n",
    "    Класс для управления процессом рендеринга с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pygame_manager: PygameManager, grid_size: int, cell_size: int):\n",
    "        \"\"\"\n",
    "        Инициализирует Renderer.\n",
    "        \"\"\"\n",
    "        self.pygame_manager = pygame_manager\n",
    "        self.grid_size = grid_size\n",
    "        self.cell_size = cell_size\n",
    "        self.screen = pygame_manager.screen\n",
    "        self.base_icons: Dict[str, pygame.Surface] = {}\n",
    "        self.text_cache: Dict[str, pygame.Rect] = {}\n",
    "        self.load_icons()\n",
    "\n",
    "    def load_icons(self) -> None:\n",
    "        \"\"\"Загружает все необходимые иконки.\"\"\"\n",
    "        try:\n",
    "            # Использование многопоточности для загрузки изображений\n",
    "            def load_all():\n",
    "                self.base_icons['agent'] = load_image(AGENT_IMG, self.cell_size)\n",
    "                self.base_icons['target'] = load_image(TARGET_IMG, self.cell_size)\n",
    "                self.base_icons['done_target'] = load_image(DONE_TARGET_IMG, self.cell_size)\n",
    "                self.base_icons['base'] = load_image(STATION_IMG, self.cell_size)\n",
    "                self.base_icons['field_bg'] = pygame.transform.smoothscale(\n",
    "                    load_image(FIELD_BACKGROUND_IMG, self.grid_size * self.cell_size),\n",
    "                    (self.grid_size * self.cell_size, self.grid_size * self.cell_size)\n",
    "                )\n",
    "                self.base_icons['field'] = pygame.transform.smoothscale(\n",
    "                    load_image(FIELD_IMG, self.grid_size * self.cell_size),\n",
    "                    (self.grid_size * self.cell_size, self.grid_size * self.cell_size)\n",
    "                )\n",
    "\n",
    "            load_thread = Thread(target=load_all)\n",
    "            load_thread.start()\n",
    "            load_thread.join()\n",
    "            logging.info(\"Иконки успешно загружены\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка загрузки иконок: {e}\")\n",
    "\n",
    "    def draw_grid(self) -> None:\n",
    "        \"\"\"Отрисовывает сетку на экране.\"\"\"\n",
    "        try:\n",
    "            grid_surface = pygame.Surface((self.grid_size * self.cell_size, self.grid_size * self.cell_size), pygame.SRCALPHA)\n",
    "            for x in range(self.grid_size):\n",
    "                for y in range(self.grid_size):\n",
    "                    pygame.draw.rect(\n",
    "                        grid_surface, BLACK,\n",
    "                        (x * self.cell_size, y * self.cell_size, self.cell_size, self.cell_size), 1\n",
    "                    )\n",
    "            self.screen.blit(grid_surface, (0, 0))\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке сетки: {e}\")\n",
    "\n",
    "    def draw_base(self, base_position: Tuple[int, int]) -> pygame.Rect:\n",
    "        \"\"\"Отрисовывает базу на экране и возвращает область обновления.\"\"\"\n",
    "        try:\n",
    "            base_size = STATION_SIZE * self.cell_size\n",
    "            base_icon_scaled = pygame.transform.smoothscale(self.base_icons['base'], (base_size, base_size))\n",
    "            rect = self.screen.blit(\n",
    "                base_icon_scaled,\n",
    "                (base_position[1] * self.cell_size, base_position[0] * self.cell_size)\n",
    "            )\n",
    "            return rect\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке базы: {e}\")\n",
    "            return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "    def draw_objects(\n",
    "        self,\n",
    "        target_positions: List[Tuple[int, int]],\n",
    "        done_status: np.ndarray,\n",
    "        obstacle_positions: Set[Tuple[int, int]],\n",
    "        current_map: np.ndarray,\n",
    "        obstacle_icons: List[pygame.Surface]\n",
    "    ) -> List[pygame.Rect]:\n",
    "        \"\"\"\n",
    "        Отрисовывает цели и препятствия на экране.\n",
    "        Возвращает список обновлённых областей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            for index, target in enumerate(target_positions):\n",
    "                x, y = target\n",
    "                if current_map[x, y, 0] != PointStatus.EMPTY.value:\n",
    "                    if index < len(done_status):\n",
    "                        icon = self.base_icons['done_target'] if done_status[index] else self.base_icons['target']\n",
    "                    else:\n",
    "                        icon = self.base_icons['target']  # По умолчанию, если индекс выходит за пределы\n",
    "                    rect = self.screen.blit(icon, (y * self.cell_size, x * self.cell_size))\n",
    "                    rects.append(rect)\n",
    "\n",
    "            for obstacle in obstacle_positions:\n",
    "                x, y = obstacle\n",
    "                if current_map[x, y, 0] != PointStatus.EMPTY.value:\n",
    "                    obstacle_icon = obstacle_icons[hash(obstacle) % len(obstacle_icons)]\n",
    "                    rect = self.screen.blit(obstacle_icon, (y * self.cell_size, x * self.cell_size))\n",
    "                    rects.append(rect)\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке объектов: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_agents(self, agents: List['Agent']) -> List[pygame.Rect]:\n",
    "        \"\"\"Отрисовывает агентов на экране и возвращает список обновлённых областей.\"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            for agent in agents:\n",
    "                if agent.position:\n",
    "                    rect = self.screen.blit(\n",
    "                        self.base_icons['agent'],\n",
    "                        (agent.position[1] * self.cell_size, agent.position[0] * self.cell_size)\n",
    "                    )\n",
    "                    rects.append(rect)\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке агентов: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_status_bar(\n",
    "        self,\n",
    "        total_reward: float,\n",
    "        step_count: int,\n",
    "        known_obstacles: int,\n",
    "        known_targets: int,\n",
    "        done_targets: int,\n",
    "        start_time: float\n",
    "    ) -> List[pygame.Rect]:\n",
    "        \"\"\"\n",
    "        Отрисовывает панель статуса.\n",
    "        Возвращает список обновлённых областей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            status_bar_rect = pygame.Rect(0, SCREEN_SIZE, SCREEN_SIZE, BAR_HEIGHT)\n",
    "            pygame.draw.rect(self.screen, WHITE, status_bar_rect)\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "\n",
    "            font_size = int(BAR_HEIGHT * 0.25)\n",
    "            font = pygame.font.SysFont('Arial', font_size)\n",
    "\n",
    "            text_x1 = SCREEN_SIZE * 0.05\n",
    "            text_x2 = SCREEN_SIZE * 0.5\n",
    "            text_y_offsets = [\n",
    "                SCREEN_SIZE + BAR_HEIGHT * 0.1,\n",
    "                SCREEN_SIZE + BAR_HEIGHT * 0.35,\n",
    "                SCREEN_SIZE + BAR_HEIGHT * 0.6\n",
    "            ]\n",
    "\n",
    "            rects = []\n",
    "            rects.append(render_text(\n",
    "                self.screen, f\"Время: {elapsed_time:.2f} сек\", font, BLACK, int(text_x1), int(text_y_offsets[0])\n",
    "            ))\n",
    "            rects.append(render_text(\n",
    "                self.screen, f\"Очки: {int(total_reward)}\", font, BLACK, int(text_x1), int(text_y_offsets[1])\n",
    "            ))\n",
    "            rects.append(render_text(\n",
    "                self.screen, f\"Шаги: {step_count}\", font, BLACK, int(text_x1), int(text_y_offsets[2])\n",
    "            ))\n",
    "\n",
    "            rects.append(render_text(\n",
    "                self.screen,\n",
    "                f\"Обнаружено препятствий: {known_obstacles}/{COUNT_OBSTACLES}\",\n",
    "                font, BLACK, int(text_x2), int(text_y_offsets[0])\n",
    "            ))\n",
    "            rects.append(render_text(\n",
    "                self.screen,\n",
    "                f\"Обнаружено целей: {known_targets}/{COUNT_TARGETS}\",\n",
    "                font, BLACK, int(text_x2), int(text_y_offsets[1])\n",
    "            ))\n",
    "            rects.append(render_text(\n",
    "                self.screen,\n",
    "                f\"Отработано целей: {done_targets}/{COUNT_TARGETS}\",\n",
    "                font, BLACK, int(text_x2), int(text_y_offsets[2])\n",
    "            ))\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отрисовке панели статуса: {e}\")\n",
    "            return []\n",
    "\n",
    "    def draw_overlay(self, current_map: np.ndarray) -> List[pygame.Rect]:\n",
    "        \"\"\"Накладывает тёмный оверлей на неизведанные области и возвращает список обновлённых областей.\"\"\"\n",
    "        try:\n",
    "            rects = []\n",
    "            dark_overlay = pygame.Surface((self.cell_size, self.cell_size), pygame.SRCALPHA)\n",
    "            dark_overlay.fill((0, 0, 0, 200))  # Непрозрачный\n",
    "\n",
    "            for x in range(self.grid_size):\n",
    "                for y in range(self.grid_size):\n",
    "                    if current_map[x, y, 0] == PointStatus.EMPTY.value:\n",
    "                        rect = self.screen.blit(dark_overlay, (y * self.cell_size, x * self.cell_size))\n",
    "                        rects.append(rect)\n",
    "            return rects\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при наложении оверлея: {e}\")\n",
    "            return []\n",
    "\n",
    "    def render_message(self, message: str, color_title: Tuple[int, int, int] = RED, color_body: Tuple[int, int, int] = GREEN) -> pygame.Rect:\n",
    "        \"\"\"\n",
    "        Отображает сообщение в центре экрана и возвращает область обновления.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.screen.fill(GRAY)\n",
    "\n",
    "            lines = message.split('\\n')\n",
    "            screen_width, screen_height = self.screen.get_size()\n",
    "\n",
    "            # Настройка шрифтов\n",
    "            font_title = pygame.font.SysFont('Arial', ceil(SCREEN_SIZE * 0.055))\n",
    "            font_body = pygame.font.SysFont('Arial', ceil(SCREEN_SIZE * 0.04))\n",
    "\n",
    "            total_height = 0\n",
    "            rects = []\n",
    "            for i, line in enumerate(lines):\n",
    "                if i == 0:\n",
    "                    font = font_title\n",
    "                    color = color_title\n",
    "                else:\n",
    "                    font = font_body\n",
    "                    color = color_body\n",
    "                text_surface = font.render(line, True, color)\n",
    "                text_width, text_height = font.size(line)\n",
    "                x = (screen_width - text_width) // 2\n",
    "                y = (screen_height - len(lines) * text_height) // 2 + total_height\n",
    "                rect = self.screen.blit(text_surface, (x, y))\n",
    "                rects.append(rect)\n",
    "                total_height += text_height + 5\n",
    "\n",
    "            pygame.display.update(rects)\n",
    "            pygame.time.wait(10)\n",
    "            return pygame.Rect(0, 0, screen_width, screen_height)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при отображении сообщения: {e}\")\n",
    "            return pygame.Rect(0, 0, 0, 0)\n",
    "\n",
    "class BaseScenario(ABC):\n",
    "    \"\"\"\n",
    "    Базовый абстрактный класс для сценариев игры.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def step(self) -> Tuple[Dict[str, Any], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"Выполняет один шаг сценария.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def reset(self) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"Сбрасывает сценарий в исходное состояние.\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def render(self) -> None:\n",
    "        \"\"\"Отображает текущее состояние сценария.\"\"\"\n",
    "        pass\n",
    "\n",
    "class Agent:\n",
    "    \"\"\"\n",
    "    Класс, представляющий агента в сценарии.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, scenario: 'SprayingScenario', name: str = None):\n",
    "        \"\"\"\n",
    "        Инициализирует агента.\n",
    "        \"\"\"\n",
    "        self.name = name or f'agent_{id(self)}'\n",
    "        self.env = scenario\n",
    "        self.position: Optional[Tuple[int, int]] = None\n",
    "        self.tank: Optional[int] = None\n",
    "        self.energy: Optional[int] = None\n",
    "        self.position_history: Optional[deque] = None\n",
    "        self.action_space = list(range(COUNT_ACTIONS))\n",
    "        self.observation_space: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    def reset(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Сбрасывает состояние агента.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.position = random.choice(list(self.env.base_positions))\n",
    "            logging.info(f\"Позиция {self.name} стартовая {self.position}\")\n",
    "            self.position_history = deque(maxlen=10)\n",
    "            self.tank = TANK_CAPACITY\n",
    "            self.energy = ENERGY_CAPACITY\n",
    "            coords = np.zeros((self.env.grid_size, self.env.grid_size, 2), dtype=np.int8)  # Изменен тип данных\n",
    "            self.observation_space = {\n",
    "                'pos': self.position,\n",
    "                'coords': coords\n",
    "            }\n",
    "            return self.observation_space\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе reset агента {self.name}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def take_action(self) -> Tuple[Tuple[int, int], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Определяет и выполняет действие агента.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "\n",
    "        try:\n",
    "            if self.tank <= 10 or self.energy <= ENERGY_CONSUMPTION_MOVE * 5:\n",
    "                logging.info(f\"{self.name} возвращается на базу из-за низкого уровня танка или энергии\")\n",
    "                path_to_base = self.env.pathfinder.find_path(\n",
    "                    start=self.position,\n",
    "                    goals=self.env.base_positions,\n",
    "                    known_map=self.env.current_map,\n",
    "                    grid_size=self.env.grid_size,\n",
    "                    occupied_positions=self.env.occupied_positions\n",
    "                )\n",
    "                if path_to_base and len(path_to_base) > 1:\n",
    "                    next_position = path_to_base[1]\n",
    "                    action = self._determine_action(self.position, next_position)\n",
    "                else:\n",
    "                    action = random.choice(self.action_space)\n",
    "            else:\n",
    "                obs = self.get_observation()\n",
    "\n",
    "                # Выбор действия на основе пути к цели или случайного действия\n",
    "                visible_targets = self.get_visible_targets(obs['coords'])\n",
    "                if visible_targets:\n",
    "                    closest_visible_target = min(\n",
    "                        visible_targets,\n",
    "                        key=lambda t: self.heuristic(self.position, t)\n",
    "                    )\n",
    "                    path = self.env.pathfinder.find_path(\n",
    "                        start=self.position,\n",
    "                        goals={closest_visible_target},\n",
    "                        known_map=obs['coords'],\n",
    "                        grid_size=self.env.grid_size,\n",
    "                        occupied_positions=self.env.occupied_positions\n",
    "                    )\n",
    "                else:\n",
    "                    path = self.env.pathfinder.find_path(\n",
    "                        start=self.position,\n",
    "                        goals=self.env.get_remaining_targets(),\n",
    "                        known_map=obs['coords'],\n",
    "                        grid_size=self.env.grid_size,\n",
    "                        occupied_positions=self.env.occupied_positions\n",
    "                    )\n",
    "\n",
    "                if path and len(path) > 1:\n",
    "                    next_position = path[1]\n",
    "                    action = self._determine_action(self.position, next_position)\n",
    "                else:\n",
    "                    action = random.choice(self.action_space)\n",
    "\n",
    "            # Выполнение действия\n",
    "            new_position, reward_increment = self.execute_action(action)\n",
    "            reward += reward_increment\n",
    "\n",
    "            return new_position, reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе take_action агента {self.name}: {e}\")\n",
    "            return self.position, 0, False, False, {}\n",
    "\n",
    "    def execute_action(self, action: int) -> Tuple[Tuple[int, int], int]:\n",
    "        \"\"\"\n",
    "        Выполняет выбранное действие и обновляет состояние агента.\n",
    "        \"\"\"\n",
    "        reward = 0\n",
    "        try:\n",
    "            # Выполнение действия\n",
    "            if action == 0:  # Вверх\n",
    "                new_position = (max(0, self.position[0] - 1), self.position[1])\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 1:  # Вниз\n",
    "                new_position = (min(self.env.grid_size - 1, self.position[0] + 1), self.position[1])\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 2:  # Влево\n",
    "                new_position = (self.position[0], max(0, self.position[1] - 1))\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            elif action == 3:  # Вправо\n",
    "                new_position = (self.position[0], min(self.env.grid_size - 1, self.position[1] + 1))\n",
    "                self.energy -= ENERGY_CONSUMPTION_MOVE\n",
    "            else:\n",
    "                new_position = self.position\n",
    "\n",
    "            obs = self.get_observation()\n",
    "            value_new_position = obs['coords'][new_position[0]][new_position[1]]\n",
    "            new_position, agent_reward = self.get_agent_rewards(new_position, value_new_position)\n",
    "            self.position = new_position\n",
    "            logging.info(f\"Действие: {action} - позиция: {self.position} - {self.name}\")\n",
    "\n",
    "            return new_position, agent_reward\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе execute_action агента {self.name}: {e}\")\n",
    "            return self.position, 0\n",
    "\n",
    "    def _determine_action(self, current: Tuple[int, int], next_pos: Tuple[int, int]) -> int:\n",
    "        \"\"\"\n",
    "        Определяет действие на основе текущей и следующей позиции.\n",
    "        \"\"\"\n",
    "        dx = next_pos[0] - current[0]\n",
    "        dy = next_pos[1] - current[1]\n",
    "        if dx == -1:\n",
    "            return 0  # Вверх\n",
    "        elif dx == 1:\n",
    "            return 1  # Вниз\n",
    "        elif dy == -1:\n",
    "            return 2  # Влево\n",
    "        elif dy == 1:\n",
    "            return 3  # Вправо\n",
    "        else:\n",
    "            return random.choice(self.action_space)\n",
    "\n",
    "    def get_observation(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Получает наблюдения агента.\n",
    "        \"\"\"\n",
    "    \n",
    "        try:\n",
    "            coords = np.zeros((self.env.grid_size, self.env.grid_size, 2), dtype=np.int8)\n",
    "            x, y = self.position\n",
    "            # Векторизация области зрения\n",
    "            x_min = max(x - VIEW_RANGE, 0)\n",
    "            x_max = min(x + VIEW_RANGE + 1, self.env.grid_size)\n",
    "            y_min = max(y - VIEW_RANGE, 0)\n",
    "            y_max = min(y + VIEW_RANGE + 1, self.env.grid_size)\n",
    "\n",
    "            coords[x_min:x_max, y_min:y_max, 0] = PointStatus.VIEWED.value\n",
    "\n",
    "            # Обновление статусов объектов с использованием Numpy\n",
    "            obstacle_indices = np.array(list(self.env.obstacle_positions))\n",
    "            remaining_targets = self.env.get_remaining_targets()\n",
    "            target_indices = np.array(list(remaining_targets))\n",
    "            if obstacle_indices.size > 0:\n",
    "                coords[obstacle_indices[:,0], obstacle_indices[:,1], 1] = ObjectStatus.OBSTACLE.value\n",
    "            if target_indices.size > 0:\n",
    "                coords[target_indices[:,0], target_indices[:,1], 1] = ObjectStatus.TARGET.value\n",
    "\n",
    "            # Объединение наблюдений\n",
    "            observation = {\n",
    "                'pos': self.position,\n",
    "                'coords': coords,\n",
    "                'energy': self.energy,\n",
    "                'tank': self.tank,\n",
    "                'visible_targets': self.get_visible_targets(coords)\n",
    "            }\n",
    "            self.observation_space = observation\n",
    "            return observation\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_observation агента {self.name}: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def get_agent_rewards(\n",
    "        self,\n",
    "        new_position: Tuple[int, int],\n",
    "        value: np.ndarray\n",
    "    ) -> Tuple[Tuple[int, int], int]:\n",
    "        \"\"\"\n",
    "        Обновляет позиции, обрабатывает препятствия и цели, начисляет награды и штрафы.\n",
    "        \"\"\"\n",
    "        agent_reward = 0\n",
    "        try:\n",
    "            self.position_history.append(new_position)\n",
    "\n",
    "            if not self.is_within_bounds(new_position):\n",
    "                agent_reward -= PENALTY_OUT_FIELD\n",
    "                logging.warning(f\"Агент {self.name} вышел за границы поля: {new_position}\")\n",
    "                new_position = self.position\n",
    "            else:\n",
    "                if value[1] == ObjectStatus.OBSTACLE.value:\n",
    "                    agent_reward -= PENALTY_OBSTACLE\n",
    "                    new_position = self.position\n",
    "                    logging.info(\n",
    "                        f\"Упс, препятствие! {self.name} - штраф {PENALTY_OBSTACLE}, вернулся на {new_position}\"\n",
    "                    )\n",
    "                elif value[1] == ObjectStatus.TARGET.value:\n",
    "                    if new_position in self.env.target_positions:\n",
    "                        index = self.env.target_positions.index(new_position)\n",
    "                        if self.env.done_status[index] == 0:\n",
    "                            self.energy -= ENERGY_CONSUMPTION_DONE\n",
    "                            self.tank -= ON_TARGET_CONSUMPTION\n",
    "                            self.env.done_status[index] = 1\n",
    "                            agent_reward += REWARD_DONE\n",
    "                            logging.info(f\"Опрыскал растение {self.name} + награда {REWARD_DONE}\")\n",
    "                else:\n",
    "                    if len(self.position_history) > 3:\n",
    "                        pos_counter = self.position_history.count(new_position)\n",
    "                        if pos_counter >= 2:\n",
    "                            if new_position == self.position_history[-2]:\n",
    "                                agent_reward -= PENALTY_LOOP * 2\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за второй раз в одну клетку {self.position_history[-2]}\"\n",
    "                                )\n",
    "                            elif 2 < pos_counter < 4:\n",
    "                                agent_reward -= PENALTY_LOOP * 3\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за вторичное посещение {new_position} в последние 10 шагов\"\n",
    "                                )\n",
    "                            elif pos_counter >= 4:\n",
    "                                agent_reward -= PENALTY_LOOP * 5\n",
    "                                logging.info(\n",
    "                                    f\"Штраф {self.name} за многократное посещение {new_position} в последние 10 шагов\"\n",
    "                                )\n",
    "            return new_position, agent_reward\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_agent_rewards агента {self.name}: {e}\")\n",
    "            return self.position, 0\n",
    "\n",
    "    def is_within_bounds(self, position: Tuple[int, int]) -> bool:\n",
    "        \"\"\"\n",
    "        Проверяет, находится ли позиция внутри границ поля.\n",
    "        \"\"\"\n",
    "        return 0 <= position[0] < self.env.grid_size and 0 <= position[1] < self.env.grid_size\n",
    "\n",
    "    def find_path_to_position(\n",
    "        self,\n",
    "        target_position: Tuple[int, int]\n",
    "    ) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к заданной позиции с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals={target_position},\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_position агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_path_to_nearest_target(self) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к ближайшей цели с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals=set(self.env.get_remaining_targets()),\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_nearest_target агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def find_path_to_nearest_base(self) -> Optional[List[Tuple[int, int]]]:\n",
    "        \"\"\"\n",
    "        Ищет путь к ближайшей базе с использованием A*.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.env.pathfinder.find_path(\n",
    "                start=self.position,\n",
    "                goals=self.env.base_positions,\n",
    "                known_map=self.env.current_map,\n",
    "                grid_size=self.env.grid_size,\n",
    "                occupied_positions=self.env.occupied_positions\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе find_path_to_nearest_base агента {self.name}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_visible_targets(self, coords: np.ndarray) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Возвращает список неполитых целей, находящихся в области зрения агента.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            visible_targets = []\n",
    "            x, y = self.position\n",
    "            x_min = max(x - VIEW_RANGE, 0)\n",
    "            x_max = min(x + VIEW_RANGE + 1, self.env.grid_size)\n",
    "            y_min = max(y - VIEW_RANGE, 0)\n",
    "            y_max = min(y + VIEW_RANGE + 1, self.env.grid_size)\n",
    "\n",
    "            # Использование векторизации для ускорения\n",
    "            visible_coords = coords[x_min:x_max, y_min:y_max, 1]\n",
    "            target_indices = np.argwhere(visible_coords == ObjectStatus.TARGET.value)\n",
    "            for dx, dy in target_indices:\n",
    "                target_pos = (x_min + dx, y_min + dy)\n",
    "                if target_pos in self.env.get_remaining_targets():\n",
    "                    visible_targets.append(target_pos)\n",
    "            return visible_targets\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_visible_targets агента {self.name}: {e}\")\n",
    "            return []\n",
    "\n",
    "    def heuristic(self, a: Tuple[int, int], b: Tuple[int, int]) -> int:\n",
    "        \"\"\"\n",
    "        Манхэттенское расстояние между двумя точками.\n",
    "        \"\"\"\n",
    "        return AStarPathfinder.heuristic(a, b)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'<Agent {self.name}>'\n",
    "\n",
    "class SprayingScenario(BaseScenario):\n",
    "    \"\"\"\n",
    "    Класс сценария опрыскивания с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_agents: int, grid_size: int, renderer: Renderer):\n",
    "        \"\"\"\n",
    "        Инициализирует сценарий опрыскивания.\n",
    "        \"\"\"\n",
    "        self.num_agents = num_agents\n",
    "        self.grid_size = grid_size\n",
    "        self.cell_size = SCREEN_SIZE // self.grid_size\n",
    "        self.margin = MARGIN_SIZE\n",
    "        self.inner_grid_size = self.grid_size - self.margin * 2\n",
    "        base_coords = (self.margin + 1, self.grid_size // 2 - STATION_SIZE // 2)\n",
    "        self.base_positions: Set[Tuple[int, int]] = {\n",
    "            (base_coords[0] + i, base_coords[1] + j)\n",
    "            for i in range(STATION_SIZE)\n",
    "            for j in range(STATION_SIZE)\n",
    "        }\n",
    "        self.agents: List[Agent] = [\n",
    "            Agent(self, name=f'agent_{i}') for i in range(self.num_agents)\n",
    "        ]\n",
    "        self.done_status = np.zeros(COUNT_TARGETS, dtype=int)\n",
    "        self.start_time: Optional[float] = None\n",
    "        self.total_reward: float = 0.0\n",
    "        self.step_reward: float = 0.0\n",
    "        self.target_positions: List[Tuple[int, int]] = []\n",
    "        self.obstacle_positions: Set[Tuple[int, int]] = set()\n",
    "        self.current_map: np.ndarray = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "        self.step_count: int = 0\n",
    "        self.obstacle_icons: List[pygame.Surface] = []\n",
    "        self.renderer = renderer\n",
    "        self.pathfinder = AStarPathfinder()\n",
    "        self.occupied_positions: Set[Tuple[int, int]] = set()\n",
    "\n",
    "    def reset_objects_positions(self) -> None:\n",
    "        \"\"\"Сбрасывает позиции объектов в сценарии.\"\"\"\n",
    "        if PLACEMENT_MODE == 'random':\n",
    "            self._randomize_positions()\n",
    "        elif PLACEMENT_MODE == 'fixed':\n",
    "            self._fixed_positions()\n",
    "        else:\n",
    "            logging.error(\"Invalid PLACEMENT_MODE. Choose 'random' or 'fixed'.\")\n",
    "            raise ValueError(\"Invalid PLACEMENT_MODE. Choose 'random' or 'fixed'.\")\n",
    "\n",
    "    def _randomize_positions(self) -> None:\n",
    "        \"\"\"Генерирует случайные позиции объектов.\"\"\"\n",
    "        try:\n",
    "            unavailable_positions = set(self.base_positions)\n",
    "            self.target_positions = self._get_objects_positions(unavailable_positions, COUNT_TARGETS)\n",
    "            unavailable_positions.update(self.target_positions)\n",
    "            self.obstacle_positions = set(self._get_objects_positions(unavailable_positions, COUNT_OBSTACLES))\n",
    "            # Проверка на окружение целей препятствиями с использованием множеств\n",
    "            while any(self._is_surrounded_by_obstacles(target) for target in self.target_positions):\n",
    "                self.obstacle_positions = set(self._get_objects_positions(unavailable_positions, COUNT_OBSTACLES))\n",
    "            logging.info(\"Случайные позиции объектов успешно сгенерированы\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _randomize_positions: {e}\")\n",
    "\n",
    "    def _fixed_positions(self) -> None:\n",
    "        \"\"\"Устанавливает фиксированные позиции объектов.\"\"\"\n",
    "        try:\n",
    "            self.target_positions = FIXED_TARGET_POSITIONS.copy()\n",
    "            self.obstacle_positions = set(FIXED_OBSTACLE_POSITIONS.copy())\n",
    "            logging.info(\"Фиксированные позиции объектов установлены\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _fixed_positions: {e}\")\n",
    "\n",
    "    def _is_surrounded_by_obstacles(self, target_position: Tuple[int, int]) -> bool:\n",
    "        \"\"\"\n",
    "        Проверяет, окружена ли цель препятствиями.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            x, y = target_position\n",
    "            step = 1\n",
    "            surrounding_positions = {\n",
    "                (x - step, y), (x + step, y), (x, y - step), (x, y + step)\n",
    "            }\n",
    "\n",
    "            obstacle_count = len(surrounding_positions & self.obstacle_positions)\n",
    "            return obstacle_count == 4\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _is_surrounded_by_obstacles: {e}\")\n",
    "            return False\n",
    "\n",
    "    def _get_available_positions(self, unavailable: Set[Tuple[int, int]]) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Получает доступные позиции для размещения объектов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            all_positions = [\n",
    "                (i, j) for i in range(self.margin, self.inner_grid_size + 1)\n",
    "                for j in range(self.margin, self.inner_grid_size + 1)\n",
    "            ]\n",
    "            available = [pos for pos in all_positions if pos not in unavailable]\n",
    "            return available\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _get_available_positions: {e}\")\n",
    "            return []\n",
    "\n",
    "    def _get_objects_positions(\n",
    "        self,\n",
    "        unavailable: Set[Tuple[int, int]],\n",
    "        size: int\n",
    "    ) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Получает список позиций объектов с учётом недоступных позиций.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            available_positions = self._get_available_positions(unavailable)\n",
    "            if len(available_positions) < size:\n",
    "                raise ValueError(\"Недостаточно доступных позиций для размещения объектов.\")\n",
    "            selected_positions = random.sample(available_positions, size)\n",
    "            return selected_positions\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _get_objects_positions: {e}\")\n",
    "            return []\n",
    "\n",
    "    def get_remaining_targets(self) -> List[Tuple[int, int]]:\n",
    "        \"\"\"Возвращает список оставшихся целей для опрыскивания.\"\"\"\n",
    "        try:\n",
    "            return [pos for pos, done in zip(self.target_positions, self.done_status) if done == 0]\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_remaining_targets: {e}\")\n",
    "            return []\n",
    "\n",
    "    def reset(self) -> Tuple[Dict[str, Any], Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Сбрасывает сценарий в исходное состояние.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.reset_objects_positions()\n",
    "            self.start_time = time.time()\n",
    "            self.step_count = 1\n",
    "            self.done_status = np.zeros(COUNT_TARGETS, dtype=int)\n",
    "            self.total_reward = 0.0\n",
    "            self.step_reward = 0.0\n",
    "            self.current_map = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "            self.obstacle_icons = load_obstacles(OBSTACLES_DIR, self.cell_size, COUNT_OBSTACLES)\n",
    "            for agent in self.agents:\n",
    "                agent.reset()\n",
    "            obs = self.get_observation()\n",
    "            logging.info(\"Перезагрузка среды\")\n",
    "            return obs, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе reset: {e}\")\n",
    "            return {}, {}\n",
    "\n",
    "    def get_observation(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Получает объединённые наблюдения от всех агентов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            combined_coords = np.zeros((self.grid_size, self.grid_size, 2), dtype=np.int8)\n",
    "            combined_energy = []\n",
    "            combined_tank = []\n",
    "            for agent in self.agents:\n",
    "                obs = agent.get_observation()\n",
    "                combined_coords = np.maximum(combined_coords, obs['coords'])\n",
    "                combined_energy.append(obs['energy'])\n",
    "                combined_tank.append(obs['tank'])\n",
    "\n",
    "            self.current_map = np.maximum(self.current_map, combined_coords)\n",
    "\n",
    "            # Обновление занятых позиций\n",
    "            self.env_update_occupied_positions()\n",
    "\n",
    "            obs = {\n",
    "                'pos': np.array([agent.position for agent in self.agents]),\n",
    "                'coords': self.current_map,\n",
    "                'energy': combined_energy,\n",
    "                'tank': combined_tank\n",
    "            }\n",
    "            return obs\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе get_observation: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def env_update_occupied_positions(self):\n",
    "        \"\"\"Обновляет множество занятых позиций для быстрого доступа.\"\"\"\n",
    "        self.occupied_positions = {agent.position for agent in self.agents if agent.position is not None}\n",
    "\n",
    "    def step(self) -> Tuple[Dict[str, Any], int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Выполняет один шаг сценария.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(f\"Шаг: {self.step_count}\")\n",
    "            obs = self.get_observation()\n",
    "            self.step_reward = 0.0\n",
    "\n",
    "            # Пакетная обработка действий агентов\n",
    "            actions = []\n",
    "            for agent in self.agents:\n",
    "                new_position, agent_reward, terminated, truncated, info = agent.take_action()\n",
    "                actions.append((agent, new_position, agent_reward))\n",
    "\n",
    "            # Обработка действий агентов\n",
    "            for agent, new_position, agent_reward in actions:\n",
    "                new_position = self.check_crash(obs, agent, new_position)\n",
    "                if 0 <= new_position[0] < self.grid_size and 0 <= new_position[1] < self.grid_size:\n",
    "                    value_position = obs['coords'][new_position[0]][new_position[1]]\n",
    "                    if value_position[0] in (PointStatus.EMPTY.value, PointStatus.VIEWED.value):\n",
    "                        if value_position[1] != ObjectStatus.TARGET.value:\n",
    "                            self.step_reward += REWARD_EXPLORE\n",
    "                            logging.info(\n",
    "                                f\"{agent.name} исследовал новую клетку {new_position} + {REWARD_EXPLORE}\"\n",
    "                            )\n",
    "                        self.current_map[new_position[0], new_position[1], 0] = PointStatus.VISITED.value\n",
    "                    agent.position = new_position\n",
    "                    self.step_reward += agent_reward\n",
    "\n",
    "            reward, terminated, truncated, info = self._check_termination_conditions()\n",
    "            self.total_reward += self.step_reward\n",
    "            self.step_count += 1\n",
    "            logging.info(\n",
    "                f\"Награда: {self.total_reward}, \"\n",
    "                f\"Завершено: {terminated}, \"\n",
    "                f\"Прервано: {truncated}\"\n",
    "            )\n",
    "\n",
    "            return obs, reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе step: {e}\")\n",
    "            return {}, 0, False, False, {}\n",
    "\n",
    "    def _check_termination_conditions(self) -> Tuple[int, bool, bool, Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Проверяет условия завершения игры: количество шагов и обработка всех целей.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            terminated = False\n",
    "            truncated = False\n",
    "            total_reward = 0\n",
    "\n",
    "            if self.step_count >= MAX_STEPS_GAME:\n",
    "                logging.info(\"Достигнуто максимальное количество шагов\")\n",
    "                truncated = True\n",
    "                total_reward = 0\n",
    "\n",
    "            elif np.all(self.done_status == 1):\n",
    "                terminated = True\n",
    "                logging.info(\"Все растения опрысканы\")\n",
    "                for agent in self.agents:\n",
    "                    agent.position = random.choice(list(self.base_positions))\n",
    "                logging.info(\"Агенты вернулись на базу\")\n",
    "\n",
    "                if self.step_count <= MIN_GAME_STEPS:\n",
    "                    total_reward = self.total_reward + REWARD_COMPLETION * 3\n",
    "                    logging.info(\n",
    "                        f\"Увеличенная награда: {total_reward} за шагов меньше, чем {MIN_GAME_STEPS}\"\n",
    "                    )\n",
    "                else:\n",
    "                    total_reward = self.total_reward + REWARD_COMPLETION\n",
    "                    logging.info(f\"Награда: {total_reward}\")\n",
    "                self.total_reward = 0.0\n",
    "            else:\n",
    "                total_reward = 0\n",
    "\n",
    "            return total_reward, terminated, truncated, {}\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе _check_termination_conditions: {e}\")\n",
    "            return 0, False, False, {}\n",
    "\n",
    "    def check_crash(\n",
    "        self,\n",
    "        obs: Dict[str, Any],\n",
    "        agent: Agent,\n",
    "        new_position: Tuple[int, int]\n",
    "    ) -> Tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Проверяет на столкновение агентов.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            collision_count = 0\n",
    "            # Использование множеств для быстрого поиска\n",
    "            if new_position in self.occupied_positions:\n",
    "                collision_count += 1\n",
    "            if collision_count > 0:\n",
    "                self.total_reward -= PENALTY_CRASH * collision_count\n",
    "                logging.warning(\n",
    "                    f\"Столкновение {collision_count} агентов в позиции {new_position}\"\n",
    "                )\n",
    "                new_position = agent.position\n",
    "            return new_position\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе check_crash: {e}\")\n",
    "            return agent.position\n",
    "\n",
    "    def render(self) -> None:\n",
    "        \"\"\"Отображает текущее состояние игры с оптимизациями.\"\"\"\n",
    "        try:\n",
    "            rects_to_update = []\n",
    "\n",
    "            # Отрисовка фона\n",
    "            self.renderer.screen.blit(self.renderer.base_icons['field_bg'], (0, 0))\n",
    "            self.renderer.screen.blit(self.renderer.base_icons['field'], (0, 0))\n",
    "            rects_to_update.extend([\n",
    "                self.renderer.base_icons['field_bg'].get_rect(),\n",
    "                self.renderer.base_icons['field'].get_rect()\n",
    "            ])\n",
    "\n",
    "            # Отрисовка сетки\n",
    "            self.renderer.draw_grid()\n",
    "\n",
    "            # Отрисовка базы\n",
    "            rect = self.renderer.draw_base(next(iter(self.base_positions)))\n",
    "            rects_to_update.append(rect)\n",
    "\n",
    "            # Отрисовка целей и препятствий\n",
    "            rects_to_update.extend(self.renderer.draw_objects(\n",
    "                target_positions=self.target_positions,\n",
    "                done_status=self.done_status,\n",
    "                obstacle_positions=self.obstacle_positions,\n",
    "                current_map=self.current_map,\n",
    "                obstacle_icons=self.obstacle_icons\n",
    "            ))\n",
    "\n",
    "            # Накладываем оверлей на неизведанные области\n",
    "            rects_to_update.extend(self.renderer.draw_overlay(self.current_map))\n",
    "\n",
    "            # Отрисовка агентов\n",
    "            rects_to_update.extend(self.renderer.draw_agents(self.agents))\n",
    "\n",
    "            # Отрисовка панели статуса\n",
    "            done_targets = int(np.sum(self.done_status))\n",
    "            known_obstacles = len(self.obstacle_positions & {\n",
    "                pos for pos in self.obstacle_positions if self.current_map[pos[0], pos[1], 0] != PointStatus.EMPTY.value\n",
    "            })\n",
    "            known_targets = len([pos for pos in self.target_positions if self.current_map[pos[0], pos[1], 0] != PointStatus.EMPTY.value])\n",
    "            rects_to_update.extend(self.renderer.draw_status_bar(\n",
    "                total_reward=self.total_reward,\n",
    "                step_count=self.step_count,\n",
    "                known_obstacles=known_obstacles,\n",
    "                known_targets=known_targets,\n",
    "                done_targets=done_targets,\n",
    "                start_time=self.start_time\n",
    "            ))\n",
    "\n",
    "            # Обновление только изменённых областей\n",
    "            pygame.display.update(rects_to_update)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе render: {e}\")\n",
    "\n",
    "    def render_full_screen(self) -> None:\n",
    "        \"\"\"\n",
    "        Рендерит начальное сообщение и настраивает экран.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.renderer.render_message(\n",
    "                \"Начало выполнения сценария\\n\\n\\n\" +\n",
    "                f\"Гиперпараметры модели:\\n\\n\"\n",
    "                f\"Темп: {LEARNING_RATE}\\n\"\n",
    "                f\"Гамма: {GAMMA}\\n\"\n",
    "                f\"Диапазон обрезки: {CLIP_RANGE}\\n\"\n",
    "                f\"Длина эпизода: {N_STEPS}\\n\"\n",
    "                f\"Энтропия: {COEF}\\n\"\n",
    "                f\"Баланс ценности: {VF_COEF}\\n\"\n",
    "                f\"Эпох: {N_EPOCHS}\\n\"\n",
    "                f\"Размер батча: {BATCH_SIZE}\\n\"\n",
    "            )\n",
    "            pygame.display.set_caption(\"OS SWARM OF DRONES\")\n",
    "            logging.info(\"Начало выполнения сценария\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе render_full_screen: {e}\")\n",
    "\n",
    "class PygameHandler:\n",
    "    \"\"\"\n",
    "    Класс для централизованного управления pygame и основным циклом игры с оптимизациями.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pygame_manager = PygameManager()\n",
    "        self.pygame_manager.create_screen(SCREEN_SIZE, SCREEN_SIZE + BAR_HEIGHT)\n",
    "        self.renderer = Renderer(\n",
    "            pygame_manager=self.pygame_manager,\n",
    "            grid_size=GRID_SIZE,\n",
    "            cell_size=SCREEN_SIZE // GRID_SIZE\n",
    "        )\n",
    "        self.scenario: Optional[SprayingScenario] = None\n",
    "\n",
    "    def run(self) -> None:\n",
    "        \"\"\"Запускает основной цикл игры.\"\"\"\n",
    "        try:\n",
    "            num_agents, grid_size, selected = self.input_screen()\n",
    "            self.scenario = SprayingScenario(num_agents, grid_size, self.renderer)\n",
    "            self.scenario.reset_objects_positions()\n",
    "            self.scenario.render_full_screen()\n",
    "\n",
    "            clock = pygame.time.Clock()\n",
    "            pygame.display.set_caption(\"Pesticide Spraying Scenario\")\n",
    "\n",
    "            obs, info = self.scenario.reset()\n",
    "            step_count = 0\n",
    "\n",
    "            while True:\n",
    "                self.handle_events()\n",
    "\n",
    "                # Удалено использование asyncio.run()\n",
    "\n",
    "                obs, reward, terminated, truncated, info = self.scenario.step()\n",
    "                self.scenario.render()\n",
    "                step_count += 1\n",
    "\n",
    "                if truncated:\n",
    "                    obs, info = self.scenario.reset()\n",
    "                    self.renderer.render_message(\"Новая миссия\")\n",
    "                    pygame.time.wait(5000)\n",
    "                    step_count = 0\n",
    "\n",
    "                if terminated:\n",
    "                    message = f\"Конец миссии, награда: {int(reward)}, шагов: {step_count}\"\n",
    "                    self.renderer.render_message(message)\n",
    "                    break\n",
    "\n",
    "                clock.tick(60)  # Поддерживаем частоту кадров\n",
    "        except KeyboardInterrupt:\n",
    "            logging.info(\"Прервано пользователем\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Произошла ошибка в основном цикле: {e}\")\n",
    "            raise\n",
    "        finally:\n",
    "            self.pygame_manager.quit()\n",
    "\n",
    "    def handle_events(self) -> None:\n",
    "        \"\"\"Обрабатывает события pygame.\"\"\"\n",
    "        try:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    sys.exit()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка при обработке событий: {e}\")\n",
    "\n",
    "    def input_screen(self) -> Tuple[int, int, int]:\n",
    "        \"\"\"\n",
    "        Отображает окно ввода для выбора количества агентов, размера поля и сценария.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Используем уже созданный screen из PygameManager\n",
    "            screen = self.pygame_manager.screen\n",
    "            renderer = self.renderer\n",
    "            font = pygame.font.Font(None, 36)\n",
    "            small_font = pygame.font.Font(None, 24)\n",
    "            clock = pygame.time.Clock()\n",
    "\n",
    "            inputs = [\n",
    "                \"Введите количество агентов:\",\n",
    "                \"Введите размер поля (минимум):\",\n",
    "                \"Выберите сценарий (1 - spraying):\"\n",
    "            ]\n",
    "            input_boxes = [pygame.Rect(150, 150 + i * 80, 300, 40) for i in range(len(inputs))]\n",
    "            input_values = [\"\", \"\", \"\"]\n",
    "\n",
    "            active_box = 0\n",
    "            finished = False\n",
    "\n",
    "            while not finished:\n",
    "                screen.fill(GRAY)\n",
    "                grid_size_min = 0  # Минимальный размер поля, обновляется динамически\n",
    "                try:\n",
    "                    num_agents = int(input_values[0]) if input_values[0].isdigit() else NUM_AGENTS\n",
    "                    grid_size_min = ceil(\n",
    "                        (COUNT_TARGETS + COUNT_OBSTACLES + int(num_agents)) ** 0.5\n",
    "                    ) + STATION_SIZE\n",
    "                except ValueError:\n",
    "                    grid_size_min = 0  # Если ввод некорректный, не рассчитываем\n",
    "\n",
    "                for event in pygame.event.get():\n",
    "                    if event.type == pygame.QUIT:\n",
    "                        pygame.quit()\n",
    "                        sys.exit()\n",
    "                    if event.type == pygame.MOUSEBUTTONDOWN:\n",
    "                        for i, box in enumerate(input_boxes):\n",
    "                            if box.collidepoint(event.pos):\n",
    "                                active_box = i\n",
    "                    if event.type == pygame.KEYDOWN:\n",
    "                        if active_box < len(inputs):\n",
    "                            if event.key == pygame.K_BACKSPACE:\n",
    "                                input_values[active_box] = input_values[active_box][:-1]\n",
    "                            elif event.key == pygame.K_RETURN:\n",
    "                                active_box += 1\n",
    "                                if active_box >= len(inputs):\n",
    "                                    finished = True\n",
    "                            else:\n",
    "                                input_values[active_box] += event.unicode\n",
    "\n",
    "                # Отрисовка подсказок и полей ввода\n",
    "                for i, text in enumerate(inputs):\n",
    "                    # Отображаем текст с выравниванием\n",
    "                    if i == 1 and grid_size_min > 0:\n",
    "                        display_text = f\"Введите размер поля (минимум: {grid_size_min}):\"\n",
    "                    else:\n",
    "                        display_text = text\n",
    "\n",
    "                    render_text(\n",
    "                        screen, display_text, small_font, (200, 200, 200), 150,\n",
    "                        120 + i * 80\n",
    "                    )\n",
    "                    color = WHITE if i == active_box else BLACK\n",
    "                    pygame.draw.rect(screen, color, input_boxes[i], 2)\n",
    "                    render_text(\n",
    "                        screen, input_values[i], font, BLACK, input_boxes[i].x + 5,\n",
    "                        input_boxes[i].y + 5\n",
    "                    )\n",
    "\n",
    "                pygame.display.flip()\n",
    "                clock.tick(30)\n",
    "\n",
    "            # Преобразование и проверка введённых данных\n",
    "            try:\n",
    "                num_agents = int(input_values[0]) if input_values[0] else NUM_AGENTS\n",
    "                grid_size = int(input_values[1]) if input_values[1] else GRID_SIZE\n",
    "                if grid_size < grid_size_min:\n",
    "                    raise ValueError(f\"Размер поля должен быть больше, чем {grid_size_min}\")\n",
    "                selected_scenario = int(input_values[2]) if input_values[2] else 1\n",
    "            except ValueError as e:\n",
    "                logging.error(f\"Ошибка ввода: {e}\")\n",
    "                renderer.render_message(f\"Ошибка ввода:\\n{e}\")\n",
    "                pygame.time.wait(3000)\n",
    "                sys.exit()\n",
    "\n",
    "            return num_agents, grid_size, selected_scenario\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Ошибка в методе input_screen: {e}\")\n",
    "            renderer.render_message(\"Ошибка ввода. Использованы значения по умолчанию.\")\n",
    "            pygame.time.wait(3000)\n",
    "            return NUM_AGENTS, GRID_SIZE, 1\n",
    "\n",
    "# =============================================================================\n",
    "# Главная функция\n",
    "# =============================================================================\n",
    "\n",
    "def run() -> None:\n",
    "    \"\"\"\n",
    "    Главная функция для запуска сценария.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pygame_handler = PygameHandler()\n",
    "        pygame_handler.run()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при запуске сценария: {e}\")\n",
    "        pygame_handler.pygame_manager.quit()\n",
    "        sys.exit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f72135-e880-4f0f-9c8c-c9f24f97b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
